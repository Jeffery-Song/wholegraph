succeed=True
[CUDA] cuda: usage: 5.74 GB
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 0},
2 :  {link #0 : 3}, {link #1 : 0}, {link #2 : 1},
3 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 0},
2 :  {link #0 : 3}, {link #1 : 0}, {link #2 : 1},
3 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 0},
2 :  {link #0 : 3}, {link #1 : 0}, {link #2 : 1},
3 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2},
0 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g2 24}, {link #2 : g3 24},
1 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g3 24}, {link #2 : g0 24},
2 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g0 24}, {link #2 : g1 24},
3 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g1 24}, {link #2 : g2 24},
0 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g2 24}, {link #2 : g3 24},
1 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g3 24}, {link #2 : g0 24},
2 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g0 24}, {link #2 : g1 24},
3 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g1 24}, {link #2 : g2 24},
0 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g2 24}, {link #2 : g3 24},
1 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g3 24}, {link #2 : g0 24},
2 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g0 24}, {link #2 : g1 24},
3 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g1 24}, {link #2 : g2 24},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 0},
2 :  {link #0 : 3}, {link #1 : 0}, {link #2 : 1},
3 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2},
0 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g2 24}, {link #2 : g3 24},
1 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g3 24}, {link #2 : g0 24},
2 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g0 24}, {link #2 : g1 24},
3 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g1 24}, {link #2 : g2 24},
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID
Set parameter TimeLimit to value 200
Set parameter MIPGap to value 0.05
Set parameter LogFile to value "cppsolver.log"
Set parameter Threads to value 40
Academic license - for non-commercial use only - registered to xiaoniu.sxn@sjtu.edu.cn
Gurobi Optimizer version 9.5.1 build v9.5.1rc2 (linux64)
Thread count: 40 physical cores, 80 logical processors, using up to 40 threads
Academic license - for non-commercial use only - registered to xiaoniu.sxn@sjtu.edu.cn
Optimize a model with 9336 rows, 3048 columns and 28664 nonzeros
Model fingerprint: 0xb458b9d9
Variable types: 5 continuous, 3043 integer (3043 binary)
Coefficient statistics:
  Matrix range     [2e-09, 5e+03]
  Objective range  [1e+00, 1e+00]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 1e+03]
Warning: Model contains large matrix coefficient range
         Consider reformulating model or setting NumericFocus parameter
         to avoid numerical issues.
Found heuristic solution: objective 5590.6710184
Presolve removed 6740 rows and 294 columns
Presolve time: 0.03s
Presolved: 2596 rows, 2754 columns, 7776 nonzeros
Variable types: 0 continuous, 2754 integer (2754 binary)
Found heuristic solution: objective 5111.9936321

Root relaxation: objective 3.404650e+03, 2071 iterations, 0.02 seconds (0.01 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0 3404.64975    0   25 5111.99363 3404.64975  33.4%     -    0s
H    0     0                    3456.3911462 3404.64975  1.50%     -    0s

Explored 1 nodes (3155 simplex iterations) in 0.09 seconds (0.06 work units)
Thread count was 40 (of 80 available processors)

Solution count 3: 3456.39 5111.99 5590.67 

Optimal solution found (tolerance 5.00e-02)
Best objective 3.456391146216e+03, best bound 3.404649753237e+03, gap 1.4970%
coll_cache:optimal_local_rate=0.134095,0.0973476,0.133986,0.148789,
coll_cache:optimal_remote_rate=0.342786,0.379534,0.342896,0.328092,
coll_cache:optimal_cpu_rate=0.523118,0.523118,0.523118,0.523118,
z=3456.39
test_result:init:feat_nbytes=375030526464
test_result:init:cache_nbytes=4125335040
test_result:init:feat_nbytes=375030526464
test_result:init:cache_nbytes=4125335040
test_result:init:feat_nbytes=375030526464
test_result:init:cache_nbytes=4125335040
test_result:init:feat_nbytes=375030526464
test_result:init:cache_nbytes=4125335040
    [Step(average) Profiler Level 1 E3 S999]
        L1  sample           0.001444 | send           0.000000
        L1  recv             0.000000 | copy           0.017014 | convert time 0.000000 | train  0.009712
        L1  feature nbytes  357.47 MB | label nbytes 0.00 Bytes
        L1  id nbytes      0.00 Bytes | graph nbytes 0.00 Bytes
        L1  miss nbytes     196.53 MB | remote nbytes  117.54 MB
        L1  num nodes               0 | num samples           0
        L1  seq duration     0.000000 | refresh duration   0.000000
    [Step(average) Profiler Level 2 E3 S999]
        L2  shuffle     0.000000 | core sample  0.000000 | id remap        0.000000
        L2  graph copy  0.000000 | id copy      0.000000 | cache feat copy 0.017014
        L2  last layer sample time 0.000000 | size 0.000000
    [Step(average) Profiler Level 3 E3 S999]
        L3  khop sample coo  0.000000 | khop sort coo      0.000000 | khop count edge     0.000000 | khop compact edge 0.000000
        L3  walk sample coo  0.000000 | walk topk total    0.000000 | walk topk step1     0.000000 | walk topk step2   0.000000
        L3  walk topk step3  0.000000 | walk topk step4    0.000000 | walk topk step5     0.000000
        L3  walk topk step6  0.000000 | walk topk step7    0.000000
        L3  remap unique     0.000000 | remap populate     0.000000 | remap mapnode       0.000000 | remap mapedge     0.000000
        L3  cache get_index  0.000225 | cache copy_index   0.000000 | cache extract_miss  0.000000
        L3  cache copy_miss  0.000000 | cache combine_miss 0.016744 | cache combine cache 0.000151 | cache combine remote 0.001074
        L3  label extract  0.000000
    [Profiler Level Percentiles E3 S999]
        p50.00_tail_logl2featcopy=0.017684
        p90.00_tail_logl2featcopy=0.018075
        p95.00_tail_logl2featcopy=0.018175
        p99.00_tail_logl2featcopy=0.018392
        p99.90_tail_logl2featcopy=0.020140
[CUDA] cuda: usage: 12.82 GB
Rank=3, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.010805, per step: 0.000043
presamping
presamping takes 3.6130406856536865
Rank=2, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.008356, per step: 0.000033
presamping
presamping takes 7.470407724380493
Rank=1, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.008151, per step: 0.000033
presamping
presamping takes 6.211082935333252
config:eval_tsp="2023-04-14 18:47:58"
config:num_worker=4
config:num_intra_size=4
config:root_dir=/nvme/songxiaoniu/graph-learning/wholegraph
config:graph_name=mag240m-homo
config:epochs=4
config:batchsize=500
config:skip_epoch=2
config:local_step=250
config:presc_epoch=2
config:neighbors=10,25
config:hiddensize=256
config:num_layer=2
config:model=sage
config:framework=dgl
config:dataloaderworkers=0
config:dropout=0.5
config:lr=0.003
config:use_nccl=False
config:use_amp=True
config:use_collcache=True
config:cache_percentage=0.01
config:cache_policy=coll_cache_asymm_link
config:omp_thread_num=40
config:unsupervised=True
config:classnum=153
config:global_barrier=<multiprocessing.synchronize.Barrier object at 0x7efe47f30460>
config:worker_id=0
creating_intra_node_communicator root=0, local_size=4, world_size=4
Rank=0, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.008263, per step: 0.000033
epoch=4 total_steps=1000
presamping
presamping takes 5.81122350692749
start training...
[Epoch 0], time=8.470162868499756, loss=0.6931472420692444
[Epoch 1], time=7.074221134185791, loss=0.6931472420692444
[Epoch 2], time=7.055016279220581, loss=0.6931472420692444
[Epoch 3], time=7.040144205093384, loss=0.6931472420692444
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   31358 KB |  199763 KB |  518400 MB |  518369 MB |
|       from large pool |   18653 KB |  190158 KB |  491509 MB |  491491 MB |
|       from small pool |   12705 KB |   18556 KB |   26890 MB |   26878 MB |
|---------------------------------------------------------------------------|
| Active memory         |   31358 KB |  199763 KB |  518400 MB |  518369 MB |
|       from large pool |   18653 KB |  190158 KB |  491509 MB |  491491 MB |
|       from small pool |   12705 KB |   18556 KB |   26890 MB |   26878 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  606208 KB |  606208 KB |  606208 KB |       0 B  |
|       from large pool |  583680 KB |  583680 KB |  583680 KB |       0 B  |
|       from small pool |   22528 KB |   22528 KB |   22528 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   19842 KB |  416598 KB |  612385 MB |  612366 MB |
|       from large pool |   16163 KB |  411887 KB |  583767 MB |  583752 MB |
|       from small pool |    3679 KB |    9684 KB |   28617 MB |   28614 MB |
|---------------------------------------------------------------------------|
| Allocations           |      62    |      81    |  213823    |  213761    |
|       from large pool |      12    |      24    |   52773    |   52761    |
|       from small pool |      50    |      66    |  161050    |  161000    |
|---------------------------------------------------------------------------|
| Active allocs         |      62    |      81    |  213823    |  213761    |
|       from large pool |      12    |      24    |   52773    |   52761    |
|       from small pool |      50    |      66    |  161050    |  161000    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      18    |      18    |      18    |       0    |
|       from large pool |       7    |       7    |       7    |       0    |
|       from small pool |      11    |      11    |      11    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      29    |      38    |   84824    |   84795    |
|       from large pool |       6    |      12    |   30770    |   30764    |
|       from small pool |      23    |      31    |   54054    |   54031    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[TRAIN_TIME] train time is 29.640795 seconds
[EPOCH_TIME] 7.410199 seconds, maybe large due to not enough epoch skipped.
[EPOCH_TIME] 7.047716 seconds

