succeed=True
[CUDA] cuda: usage: 5.33 GB
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 0},
2 :  {link #0 : 3}, {link #1 : 0}, {link #2 : 1},
3 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 0},
2 :  {link #0 : 3}, {link #1 : 0}, {link #2 : 1},
3 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 0},
2 :  {link #0 : 3}, {link #1 : 0}, {link #2 : 1},
3 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2},
0 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g2 24}, {link #2 : g3 24},
1 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g3 24}, {link #2 : g0 24},
2 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g0 24}, {link #2 : g1 24},
3 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g1 24}, {link #2 : g2 24},
0 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g2 24}, {link #2 : g3 24},
1 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g3 24}, {link #2 : g0 24},
2 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g0 24}, {link #2 : g1 24},
3 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g1 24}, {link #2 : g2 24},
0 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g2 24}, {link #2 : g3 24},
1 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g3 24}, {link #2 : g0 24},
2 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g0 24}, {link #2 : g1 24},
3 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g1 24}, {link #2 : g2 24},
0 :  {link #0 : 1}, {link #1 : 2}, {link #2 : 3},
1 :  {link #0 : 2}, {link #1 : 3}, {link #2 : 0},
2 :  {link #0 : 3}, {link #1 : 0}, {link #2 : 1},
3 :  {link #0 : 0}, {link #1 : 1}, {link #2 : 2},
0 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g2 24}, {link #2 : g3 24},
1 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g3 24}, {link #2 : g0 24},
2 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g0 24}, {link #2 : g1 24},
3 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g1 24}, {link #2 : g2 24},
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID
Set parameter TimeLimit to value 200
Set parameter MIPGap to value 0.05
Set parameter LogFile to value "cppsolver.log"
Set parameter Threads to value 40
Academic license - for non-commercial use only - registered to xiaoniu.sxn@sjtu.edu.cn
Gurobi Optimizer version 9.5.1 build v9.5.1rc2 (linux64)
Thread count: 40 physical cores, 80 logical processors, using up to 40 threads
Academic license - for non-commercial use only - registered to xiaoniu.sxn@sjtu.edu.cn
Optimize a model with 23168 rows, 7570 columns and 71224 nonzeros
Model fingerprint: 0x706a6a2a
Variable types: 5 continuous, 7565 integer (7565 binary)
Coefficient statistics:
  Matrix range     [8e-09, 5e+03]
  Objective range  [1e+00, 1e+00]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 2e+03]
Found heuristic solution: objective 10044.435133
Presolve removed 16058 rows and 37 columns
Presolve time: 0.10s
Presolved: 7110 rows, 7533 columns, 34122 nonzeros
Variable types: 1 continuous, 7532 integer (7531 binary)

Root relaxation: objective 1.657953e+03, 6461 iterations, 0.10 seconds (0.07 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0 1657.95317    0   29 10044.4351 1657.95317  83.5%     -    0s
H    0     0                    1666.8204562 1657.95317  0.53%     -    0s

Explored 1 nodes (8760 simplex iterations) in 0.29 seconds (0.22 work units)
Thread count was 40 (of 80 available processors)

Solution count 2: 1666.82 10044.4 

Optimal solution found (tolerance 5.00e-02)
Best objective 1.666820456170e+03, best bound 1.657953172939e+03, gap 0.5320%
coll_cache:optimal_local_rate=0.226302,0.223659,0.211301,0.246168,
coll_cache:optimal_remote_rate=0.677125,0.679768,0.692125,0.657259,
coll_cache:optimal_cpu_rate=0.0965733,0.0965733,0.0965733,0.0965733,
z=1666.82
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=5441819648
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=5441819648
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=5441819648
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=5441819648
    [Step(average) Profiler Level 1 E3 S123]
        L1  sample           0.003578 | send           0.000000
        L1  recv             0.000000 | copy           0.013235 | convert time 0.000000 | train  0.009100
        L1  feature nbytes    1.13 GB | label nbytes 0.00 Bytes
        L1  id nbytes      0.00 Bytes | graph nbytes 0.00 Bytes
        L1  miss nbytes     142.94 MB | remote nbytes  762.46 MB
        L1  num nodes               0 | num samples           0
        L1  seq duration     0.000000 | refresh duration   0.000000
    [Step(average) Profiler Level 2 E3 S123]
        L2  shuffle     0.000000 | core sample  0.000000 | id remap        0.000000
        L2  graph copy  0.000000 | id copy      0.000000 | cache feat copy 0.013235
        L2  last layer sample time 0.000000 | size 0.000000
    [Step(average) Profiler Level 3 E3 S123]
        L3  khop sample coo  0.000000 | khop sort coo      0.000000 | khop count edge     0.000000 | khop compact edge 0.000000
        L3  walk sample coo  0.000000 | walk topk total    0.000000 | walk topk step1     0.000000 | walk topk step2   0.000000
        L3  walk topk step3  0.000000 | walk topk step4    0.000000 | walk topk step5     0.000000
        L3  walk topk step6  0.000000 | walk topk step7    0.000000
        L3  remap unique     0.000000 | remap populate     0.000000 | remap mapnode       0.000000 | remap mapedge     0.000000
        L3  cache get_index  0.000903 | cache copy_index   0.000000 | cache extract_miss  0.000000
        L3  cache copy_miss  0.000000 | cache combine_miss 0.012282 | cache combine cache 0.000689 | cache combine remote 0.006615
        L3  label extract  0.000000
    [Profiler Level Percentiles E3 S123]
        p50.00_tail_logl2featcopy=0.013174
        p90.00_tail_logl2featcopy=0.013545
        p95.00_tail_logl2featcopy=0.013629
        p99.00_tail_logl2featcopy=0.018896
        p99.90_tail_logl2featcopy=0.021267
[CUDA] cuda: usage: 14.82 GB
Rank=3, Graph loaded.
!!!!Train_dataloader(with 31 items) enumerate latency: 0.5024809837341309
!!!!Train_data_list(with 31 items) enumerate latency: 5.9604644775390625e-06, transfer latency: 0.42818617820739746
presamping
presamping takes 2.7599663734436035
config:eval_tsp="2023-04-14 20:06:57"
config:num_worker=4
config:num_intra_size=4
config:root_dir=/nvme/songxiaoniu/graph-learning/wholegraph
config:graph_name=com-friendster
config:epochs=4
config:batchsize=8000
config:skip_epoch=2
config:local_step=250
config:presc_epoch=2
config:neighbors=10,25
config:hiddensize=256
config:num_layer=2
config:model=sage
config:framework=dgl
config:dataloaderworkers=0
config:dropout=0.5
config:lr=0.003
config:use_nccl=False
config:use_amp=True
config:use_collcache=True
config:cache_percentage=0.08
config:cache_policy=coll_cache_asymm_link
config:omp_thread_num=40
config:unsupervised=False
config:classnum=100
config:global_barrier=<multiprocessing.synchronize.Barrier object at 0x7fb5240b9430>
config:worker_id=0
creating_intra_node_communicator root=0, local_size=4, world_size=4
Rank=0, Graph loaded.
!!!!Train_dataloader(with 31 items) enumerate latency: 0.5048360824584961
!!!!Train_data_list(with 31 items) enumerate latency: 6.4373016357421875e-06, transfer latency: 0.42233705520629883
epoch=4 total_steps=124
presamping
presamping takes 2.0216615200042725
start training...
[Epoch 0], time=2.1069703102111816, loss=4.427171230316162
[Epoch 1], time=0.8103861808776855, loss=4.243779182434082
[Epoch 2], time=0.8017618656158447, loss=4.061141014099121
[Epoch 3], time=0.8036596775054932, loss=3.879349946975708
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 2         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   72748 KB |  749426 KB |  202452 MB |  202381 MB |
|       from large pool |   66058 KB |  743234 KB |  200595 MB |  200530 MB |
|       from small pool |    6690 KB |    8779 KB |    1857 MB |    1850 MB |
|---------------------------------------------------------------------------|
| Active memory         |   72748 KB |  749426 KB |  202452 MB |  202381 MB |
|       from large pool |   66058 KB |  743234 KB |  200595 MB |  200530 MB |
|       from small pool |    6690 KB |    8779 KB |    1857 MB |    1850 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |     788 MB |    1332 MB |    3230 MB |    2442 MB |
|       from large pool |     776 MB |    1322 MB |    3218 MB |    2442 MB |
|       from small pool |      12 MB |      12 MB |      12 MB |       0 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   50131 KB |  684633 KB |  180177 MB |  180128 MB |
|       from large pool |   46582 KB |  680724 KB |  178280 MB |  178235 MB |
|       from small pool |    3549 KB |    5397 KB |    1896 MB |    1892 MB |
|---------------------------------------------------------------------------|
| Allocations           |      55    |      69    |   19722    |   19667    |
|       from large pool |      11    |      22    |    7158    |    7147    |
|       from small pool |      44    |      49    |   12564    |   12520    |
|---------------------------------------------------------------------------|
| Active allocs         |      55    |      69    |   19722    |   19667    |
|       from large pool |      11    |      22    |    7158    |    7147    |
|       from small pool |      44    |      49    |   12564    |   12520    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      16    |      16    |      26    |      10    |
|       from large pool |      10    |      10    |      20    |      10    |
|       from small pool |       6    |       6    |       6    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      22    |      34    |    7499    |    7477    |
|       from large pool |       6    |      14    |    4134    |    4128    |
|       from small pool |      16    |      24    |    3365    |    3349    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[TRAIN_TIME] train time is 4.523679 seconds
[EPOCH_TIME] 1.130920 seconds, maybe large due to not enough epoch skipped.
[EPOCH_TIME] 0.802808 seconds
Rank=2, Graph loaded.
!!!!Train_dataloader(with 31 items) enumerate latency: 0.5305163860321045
!!!!Train_data_list(with 31 items) enumerate latency: 6.9141387939453125e-06, transfer latency: 0.4436914920806885
presamping
presamping takes 2.846548557281494
Rank=1, Graph loaded.
!!!!Train_dataloader(with 31 items) enumerate latency: 0.5211737155914307
!!!!Train_data_list(with 31 items) enumerate latency: 6.9141387939453125e-06, transfer latency: 0.43296289443969727
presamping
presamping takes 2.9601449966430664

