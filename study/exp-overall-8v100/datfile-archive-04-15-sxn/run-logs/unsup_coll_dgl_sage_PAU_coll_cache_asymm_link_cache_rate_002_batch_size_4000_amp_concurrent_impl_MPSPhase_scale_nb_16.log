succeed=True
[CUDA] cuda: usage: 5.38 GB
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID
Set parameter TimeLimit to value 200
Set parameter MIPGap to value 0.05
Set parameter ScaleFlag to value 1
Set parameter DegenMoves to value 2
Set parameter Cuts to value 2
Set parameter LogFile to value "cppsolver.log"
Set parameter Threads to value 48
Academic license - for non-commercial use only - registered to xiaoniu.sxn@sjtu.edu.cn
Gurobi Optimizer version 9.5.2 build v9.5.2rc0 (linux64)
Thread count: 48 physical cores, 96 logical processors, using up to 48 threads
Academic license - for non-commercial use only - registered to xiaoniu.sxn@sjtu.edu.cn
Optimize a model with 145792 rows, 22641 columns and 366584 nonzeros
Model fingerprint: 0x79f592a2
Variable types: 9 continuous, 22632 integer (22632 binary)
Coefficient statistics:
  Matrix range     [5e-09, 6e+05]
  Objective range  [1e+00, 1e+00]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 7e+04]
Warning: Model contains large matrix coefficient range
         Consider reformulating model or setting NumericFocus parameter
         to avoid numerical issues.
Found heuristic solution: objective 380682.49553
Presolve removed 123904 rows and 214 columns
Presolve time: 0.33s
Presolved: 21888 rows, 22427 columns, 65640 nonzeros
Variable types: 0 continuous, 22427 integer (22427 binary)
Found heuristic solution: objective 378695.32720

Root relaxation: objective 2.308413e+05, 27653 iterations, 1.19 seconds (1.00 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0 230841.324    0 10841 378695.327 230841.324  39.0%     -    1s
H    0     0                    378641.68682 230841.324  39.0%     -    1s
H    0     0                    338876.92897 230841.324  31.9%     -    1s
H    0     0                    327526.89378 230841.324  29.5%     -    4s
H    0     0                    314688.81307 230841.324  26.6%     -    4s
H    0     0                    300760.17260 230841.324  23.2%     -    4s
H    0     0                    293985.94737 230841.324  21.5%     -    4s
H    0     0                    286043.65799 230841.324  19.3%     -    4s
H    0     0                    278015.38918 238904.661  14.1%     -    5s
     0     0 238906.892    0 6396 278015.389 238906.892  14.1%     -    5s
H    0     0                    262650.08099 238906.892  9.04%     -    7s
     0     0 241519.661    0 5139 262650.081 241519.661  8.05%     -    8s
     0     0 241519.661    0 5114 262650.081 241519.661  8.05%     -    8s
     0     0 243067.551    0 4851 262650.081 243067.551  7.46%     -   10s
H    0     0                    259107.88983 243067.551  6.19%     -   10s
     0     0 245723.663    0 2667 259107.890 245723.663  5.17%     -   11s
     0     0 246192.346    0 2259 259107.890 246192.346  4.98%     -   11s

Cutting planes:
  Gomory: 242
  Lift-and-project: 65
  Flow cover: 9
  Zero half: 1115
  Mod-K: 1960

Explored 1 nodes (38837 simplex iterations) in 11.40 seconds (9.01 work units)
Thread count was 48 (of 96 available processors)

Solution count 10: 259108 262650 278015 ... 378642

Optimal solution found (tolerance 5.00e-02)
Best objective 2.591078898328e+05, best bound 2.461923461900e+05, gap 4.9846%
coll_cache:optimal_local_rate=0.136891,0.100619,0.0899582,0.106555,0.108241,0.124792,0.106401,0.0888648,
coll_cache:optimal_remote_rate=0.25841,0.294682,0.305342,0.288745,0.28706,0.270508,0.2889,0.306436,
coll_cache:optimal_cpu_rate=0.604699,0.604699,0.604699,0.604699,0.604699,0.604699,0.604699,0.604699,
z=259108
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=1194116608
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=1194116608
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=1194116608
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=1194116608
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=1194116608
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=1194116608
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=1194116608
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=1194116608
    [Step(average) Profiler Level 1 E3 S999]
        L1  sample           0.007847 | send           0.000000
        L1  recv             0.000000 | copy           0.191349 | convert time 0.000000 | train  0.020381
        L1  feature nbytes    1.07 GB | label nbytes 0.00 Bytes
        L1  id nbytes      0.00 Bytes | graph nbytes 0.00 Bytes
        L1  miss nbytes     663.44 MB | remote nbytes  311.95 MB
        L1  num nodes               0 | num samples           0
        L1  seq duration     0.000000 | refresh duration   0.000000
    [Step(average) Profiler Level 2 E3 S999]
        L2  shuffle     0.000000 | core sample  0.000000 | id remap        0.000000
        L2  graph copy  0.000000 | id copy      0.000000 | cache feat copy 0.191349
        L2  last layer sample time 0.000000 | size 0.000000
    [Step(average) Profiler Level 3 E3 S999]
        L3  khop sample coo  0.000000 | khop sort coo      0.000000 | khop count edge     0.000000 | khop compact edge 0.000000
        L3  walk sample coo  0.000000 | walk topk total    0.000000 | walk topk step1     0.000000 | walk topk step2   0.000000
        L3  walk topk step3  0.000000 | walk topk step4    0.000000 | walk topk step5     0.000000
        L3  walk topk step6  0.000000 | walk topk step7    0.000000
        L3  remap unique     0.000000 | remap populate     0.000000 | remap mapnode       0.000000 | remap mapedge     0.000000
        L3  cache get_index  0.001811 | cache copy_index   0.000000 | cache extract_miss  0.000000
        L3  cache copy_miss  0.000000 | cache combine_miss 0.189447 | cache combine cache 0.001935 | cache combine remote 0.003360
        L3  label extract  0.000000
    [Profiler Level Percentiles E3 S999]
        p50.00_tail_logl2featcopy=0.191845
        p90.00_tail_logl2featcopy=0.200421
        p95.00_tail_logl2featcopy=0.202227
        p99.00_tail_logl2featcopy=0.204258
        p99.90_tail_logl2featcopy=0.205627
[CUDA] cuda: usage: 11.81 GB
config:eval_tsp="2023-04-14 20:19:32"
config:num_worker=8
config:num_intra_size=4
config:root_dir=/nvme/songxiaoniu/graph-learning/wholegraph
config:graph_name=ogbn-papers100M
config:epochs=4
config:batchsize=4000
config:skip_epoch=2
config:local_step=125
config:presc_epoch=2
config:neighbors=10,25
config:hiddensize=256
config:num_layer=2
config:model=sage
config:framework=dgl
config:dataloaderworkers=0
config:dropout=0.5
config:lr=0.003
config:use_nccl=False
config:use_amp=True
config:use_collcache=True
config:cache_percentage=0.02
config:cache_policy=coll_cache_asymm_link
config:omp_thread_num=48
config:unsupervised=True
config:classnum=172
config:global_barrier=<multiprocessing.synchronize.Barrier object at 0x7f3c0fbb6400>
config:worker_id=0
creating_intra_node_communicator root=0, local_size=4, world_size=8
Rank=0, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.005709, per step: 0.000046
epoch=4 total_steps=500
presamping
presamping takes 22.506016492843628
start training...
[Epoch 0], time=29.07195496559143, loss=0.6931472420692444
[Epoch 1], time=27.460248708724976, loss=0.6931472420692444
[Epoch 2], time=27.434568405151367, loss=0.6931472420692444
[Epoch 3], time=27.474533796310425, loss=0.6931472420692444
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  140973 KB |     786 MB |    1207 GB |    1207 GB |
|       from large pool |  130846 KB |     777 MB |    1194 GB |    1193 GB |
|       from small pool |   10126 KB |      14 MB |      13 GB |      13 GB |
|---------------------------------------------------------------------------|
| Active memory         |  140973 KB |     786 MB |    1207 GB |    1207 GB |
|       from large pool |  130846 KB |     777 MB |    1194 GB |    1193 GB |
|       from small pool |   10126 KB |      14 MB |      13 GB |      13 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1916 MB |    1916 MB |    1916 MB |       0 B  |
|       from large pool |    1896 MB |    1896 MB |    1896 MB |       0 B  |
|       from small pool |      20 MB |      20 MB |      20 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   76115 KB |     903 MB |    1303 GB |    1303 GB |
|       from large pool |   69857 KB |     897 MB |    1289 GB |    1289 GB |
|       from small pool |    6257 KB |       9 MB |      14 GB |      14 GB |
|---------------------------------------------------------------------------|
| Allocations           |      58    |      74    |  102467    |  102409    |
|       from large pool |      11    |      21    |   32294    |   32283    |
|       from small pool |      47    |      58    |   70173    |   70126    |
|---------------------------------------------------------------------------|
| Active allocs         |      58    |      74    |  102467    |  102409    |
|       from large pool |      11    |      21    |   32294    |   32283    |
|       from small pool |      47    |      58    |   70173    |   70126    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      25    |      25    |      25    |       0    |
|       from large pool |      15    |      15    |      15    |       0    |
|       from small pool |      10    |      10    |      10    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      33    |      42    |   34747    |   34714    |
|       from large pool |      12    |      18    |   17298    |   17286    |
|       from small pool |      21    |      29    |   17449    |   17428    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[TRAIN_TIME] train time is 111.442858 seconds
[EPOCH_TIME] 27.860714 seconds, maybe large due to not enough epoch skipped.
[EPOCH_TIME] 27.454772 seconds
Rank=3, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.012171, per step: 0.000097
presamping
presamping takes 22.38716959953308
Rank=6, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.005774, per step: 0.000046
presamping
presamping takes 21.950477361679077
Rank=7, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.005620, per step: 0.000045
presamping
presamping takes 21.192602396011353
Rank=1, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.012152, per step: 0.000097
presamping
presamping takes 22.566783905029297
creating_intra_node_communicator root=4, local_size=4, world_size=8
Rank=4, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.007381, per step: 0.000059
presamping
presamping takes 22.201900720596313
Rank=2, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.006988, per step: 0.000056
presamping
presamping takes 22.183555364608765
Rank=5, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.005651, per step: 0.000045
presamping
presamping takes 22.946244478225708

