succeed=True
[CUDA] cuda: usage: 5.29 GB
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID
Set parameter TimeLimit to value 200
Set parameter MIPGap to value 0.05
Set parameter ScaleFlag to value 1
Set parameter DegenMoves to value 2
Set parameter Cuts to value 2
Set parameter LogFile to value "cppsolver.log"
Set parameter Threads to value 48
Academic license - for non-commercial use only - registered to xiaoniu.sxn@sjtu.edu.cn
Gurobi Optimizer version 9.5.2 build v9.5.2rc0 (linux64)
Thread count: 48 physical cores, 96 logical processors, using up to 48 threads
Academic license - for non-commercial use only - registered to xiaoniu.sxn@sjtu.edu.cn
Optimize a model with 149752 rows, 23256 columns and 376544 nonzeros
Model fingerprint: 0xc32a45e4
Variable types: 9 continuous, 23247 integer (23247 binary)
Coefficient statistics:
  Matrix range     [5e-09, 3e+05]
  Objective range  [1e+00, 1e+00]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 3e+04]
Warning: Model contains large matrix coefficient range
         Consider reformulating model or setting NumericFocus parameter
         to avoid numerical issues.
Found heuristic solution: objective 194890.93169
Presolve removed 127224 rows and 173 columns
Presolve time: 0.36s
Presolved: 22528 rows, 23083 columns, 67560 nonzeros
Variable types: 0 continuous, 23083 integer (23083 binary)
Found heuristic solution: objective 192455.88537

Root relaxation: objective 1.157764e+05, 28201 iterations, 1.23 seconds (1.15 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0 115776.442    0 11401 192455.885 115776.442  39.8%     -    2s
H    0     0                    191028.90413 115776.442  39.4%     -    2s
H    0     0                    169245.38237 115776.442  31.6%     -    2s
H    0     0                    168004.79796 115776.442  31.1%     -    6s
H    0     0                    164103.23610 115776.444  29.4%     -    6s
     0     0 118165.315    0 8999 164103.236 118165.315  28.0%     -    8s
H    0     0                    162127.54703 118165.315  27.1%     -    9s
H    0     0                    150541.85459 118165.315  21.5%     -    9s
H    0     0                    149678.79611 119429.208  20.2%     -   10s
     0     0 119558.619    0 7476 149678.796 119558.619  20.1%     -   10s
     0     0 119558.619    0 7468 149678.796 119558.619  20.1%     -   10s
     0     0 120873.810    0 7884 149678.796 120873.810  19.2%     -   12s
H    0     0                    149111.03479 120873.810  18.9%     -   12s
H    0     0                    146020.65872 120873.810  17.2%     -   12s
H    0     0                    144682.24076 121290.345  16.2%     -   13s
     0     0 121290.345    0 8449 144682.241 121290.345  16.2%     -   13s
H    0     0                    140045.18160 121380.496  13.3%     -   13s
     0     0 121380.496    0 8640 140045.182 121380.496  13.3%     -   13s
     0     0 121674.886    0 8402 140045.182 121674.886  13.1%     -   14s
     0     0 121930.686    0 8143 140045.182 121930.686  12.9%     -   15s
H    0     0                    136271.33239 122533.812  10.1%     -   16s
     0     0 122533.812    0 7592 136271.332 122533.812  10.1%     -   16s
     0     0 122649.660    0 7363 136271.332 122649.660  10.0%     -   17s
     0     0 122663.622    0 7444 136271.332 122663.622  10.0%     -   17s
     0     0 122675.833    0 7390 136271.332 122675.833  10.0%     -   17s
     0     0 122683.734    0 7395 136271.332 122683.734  10.0%     -   18s
     0     0 122687.257    0 7362 136271.332 122687.257  10.0%     -   19s
     0     0 122687.730    0 7310 136271.332 122687.730  10.0%     -   19s
H    0     0                    134920.97822 122687.730  9.07%     -   21s
     0     0 122688.876    0 7215 134920.978 122688.876  9.07%     -   21s
H    0     0                    129577.84270 122688.876  5.32%     -   25s
     0     0 123867.562    0 2514 129577.843 123867.562  4.41%     -   26s

Cutting planes:
  Gomory: 202
  Lift-and-project: 45
  MIR: 94
  Flow cover: 16
  Zero half: 5783
  Mod-K: 2381

Explored 1 nodes (75021 simplex iterations) in 26.26 seconds (23.56 work units)
Thread count was 48 (of 96 available processors)

Solution count 10: 129578 134921 136271 ... 162128

Optimal solution found (tolerance 5.00e-02)
Best objective 1.295778426967e+05, best bound 1.238675620927e+05, gap 4.4068%
coll_cache:optimal_local_rate=0.106544,0.103925,0.121864,0.107318,0.111339,0.112899,0.112939,0.101121,
coll_cache:optimal_remote_rate=0.307502,0.310121,0.292182,0.306728,0.302707,0.301147,0.301107,0.312926,
coll_cache:optimal_cpu_rate=0.585953,0.585953,0.585953,0.585953,0.585953,0.585953,0.585953,0.585953,
z=129578
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=1194116608
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=1194116608
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=1194116608
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=1194116608
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=1194116608
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=1194116608
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=1194116608
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=1194116608
    [Step(average) Profiler Level 1 E3 S999]
        L1  sample           0.004445 | send           0.000000
        L1  recv             0.000000 | copy           0.100865 | convert time 0.000000 | train  0.011319
        L1  feature nbytes  563.18 MB | label nbytes 0.00 Bytes
        L1  id nbytes      0.00 Bytes | graph nbytes 0.00 Bytes
        L1  miss nbytes     332.93 MB | remote nbytes  169.13 MB
        L1  num nodes               0 | num samples           0
        L1  seq duration     0.000000 | refresh duration   0.000000
    [Step(average) Profiler Level 2 E3 S999]
        L2  shuffle     0.000000 | core sample  0.000000 | id remap        0.000000
        L2  graph copy  0.000000 | id copy      0.000000 | cache feat copy 0.100865
        L2  last layer sample time 0.000000 | size 0.000000
    [Step(average) Profiler Level 3 E3 S999]
        L3  khop sample coo  0.000000 | khop sort coo      0.000000 | khop count edge     0.000000 | khop compact edge 0.000000
        L3  walk sample coo  0.000000 | walk topk total    0.000000 | walk topk step1     0.000000 | walk topk step2   0.000000
        L3  walk topk step3  0.000000 | walk topk step4    0.000000 | walk topk step5     0.000000
        L3  walk topk step6  0.000000 | walk topk step7    0.000000
        L3  remap unique     0.000000 | remap populate     0.000000 | remap mapnode       0.000000 | remap mapedge     0.000000
        L3  cache get_index  0.000830 | cache copy_index   0.000000 | cache extract_miss  0.000000
        L3  cache copy_miss  0.000000 | cache combine_miss 0.099939 | cache combine cache 0.001075 | cache combine remote 0.002021
        L3  label extract  0.000000
    [Profiler Level Percentiles E3 S999]
        p50.00_tail_logl2featcopy=0.101415
        p90.00_tail_logl2featcopy=0.104863
        p95.00_tail_logl2featcopy=0.105564
        p99.00_tail_logl2featcopy=0.106678
        p99.90_tail_logl2featcopy=0.113376
[CUDA] cuda: usage: 10.74 GB
Rank=7, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.004737, per step: 0.000038
presamping
presamping takes 12.692389488220215
config:eval_tsp="2023-04-14 18:37:23"
config:num_worker=8
config:num_intra_size=4
config:root_dir=/nvme/songxiaoniu/graph-learning/wholegraph
config:graph_name=ogbn-papers100M
config:epochs=4
config:batchsize=2000
config:skip_epoch=2
config:local_step=125
config:presc_epoch=2
config:neighbors=10,25
config:hiddensize=256
config:num_layer=2
config:model=sage
config:framework=dgl
config:dataloaderworkers=0
config:dropout=0.5
config:lr=0.003
config:use_nccl=False
config:use_amp=True
config:use_collcache=True
config:cache_percentage=0.02
config:cache_policy=coll_cache_asymm_link
config:omp_thread_num=48
config:unsupervised=True
config:classnum=172
config:global_barrier=<multiprocessing.synchronize.Barrier object at 0x7fba8dec0400>
config:worker_id=0
creating_intra_node_communicator root=0, local_size=4, world_size=8
Rank=0, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.004648, per step: 0.000037
epoch=4 total_steps=500
presamping
presamping takes 12.604219675064087
start training...
[Epoch 0], time=16.038034915924072, loss=0.6931472420692444
[Epoch 1], time=14.552109956741333, loss=0.6931472420692444
[Epoch 2], time=14.594922065734863, loss=0.6931472420692444
[Epoch 3], time=14.61589503288269, loss=0.6931472420692444
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   75622 KB |  415928 KB |  645969 MB |  645895 MB |
|       from large pool |   68605 KB |  409493 KB |  637817 MB |  637750 MB |
|       from small pool |    7017 KB |    8900 KB |    8152 MB |    8145 MB |
|---------------------------------------------------------------------------|
| Active memory         |   75622 KB |  415928 KB |  645969 MB |  645895 MB |
|       from large pool |   68605 KB |  409493 KB |  637817 MB |  637750 MB |
|       from small pool |    7017 KB |    8900 KB |    8152 MB |    8145 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1254 MB |    1254 MB |    1254 MB |       0 B  |
|       from large pool |    1242 MB |    1242 MB |    1242 MB |       0 B  |
|       from small pool |      12 MB |      12 MB |      12 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   32921 KB |  477175 KB |  753428 MB |  753396 MB |
|       from large pool |   29699 KB |  473678 KB |  745086 MB |  745057 MB |
|       from small pool |    3222 KB |    6411 KB |    8342 MB |    8339 MB |
|---------------------------------------------------------------------------|
| Allocations           |      58    |      74    |  102449    |  102391    |
|       from large pool |      11    |      21    |   31278    |   31267    |
|       from small pool |      47    |      58    |   71171    |   71124    |
|---------------------------------------------------------------------------|
| Active allocs         |      58    |      74    |  102449    |  102391    |
|       from large pool |      11    |      21    |   31278    |   31267    |
|       from small pool |      47    |      58    |   71171    |   71124    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      18    |      18    |      18    |       0    |
|       from large pool |      12    |      12    |      12    |       0    |
|       from small pool |       6    |       6    |       6    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      18    |      35    |   34670    |   34652    |
|       from large pool |       5    |      15    |   16859    |   16854    |
|       from small pool |      13    |      24    |   17811    |   17798    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[TRAIN_TIME] train time is 59.802305 seconds
[EPOCH_TIME] 14.950576 seconds, maybe large due to not enough epoch skipped.
[EPOCH_TIME] 14.605604 seconds
Rank=5, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.004801, per step: 0.000038
presamping
presamping takes 13.7608642578125
creating_intra_node_communicator root=4, local_size=4, world_size=8
Rank=4, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.005490, per step: 0.000044
presamping
presamping takes 12.756236553192139
Rank=3, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.007631, per step: 0.000061
presamping
presamping takes 13.150058031082153
Rank=1, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.007557, per step: 0.000060
presamping
presamping takes 13.784035921096802
Rank=6, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.004726, per step: 0.000038
presamping
presamping takes 11.622435331344604
Rank=2, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.005142, per step: 0.000041
presamping
presamping takes 13.597510814666748

