succeed=True
[CUDA] cuda: usage: 5.32 GB
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID
Set parameter TimeLimit to value 200
Set parameter MIPGap to value 0.05
Set parameter ScaleFlag to value 1
Set parameter DegenMoves to value 2
Set parameter Cuts to value 2
Set parameter LogFile to value "cppsolver.log"
Set parameter Threads to value 48
Academic license - for non-commercial use only - registered to xiaoniu.sxn@sjtu.edu.cn
Gurobi Optimizer version 9.5.2 build v9.5.2rc0 (linux64)
Thread count: 48 physical cores, 96 logical processors, using up to 48 threads
Academic license - for non-commercial use only - registered to xiaoniu.sxn@sjtu.edu.cn
Optimize a model with 134176 rows, 20837 columns and 337368 nonzeros
Model fingerprint: 0x6bac6a96
Variable types: 9 continuous, 20828 integer (20828 binary)
Coefficient statistics:
  Matrix range     [8e-09, 7e+04]
  Objective range  [1e+00, 1e+00]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 1e+05]
Warning: Model contains large matrix coefficient range
         Consider reformulating model or setting NumericFocus parameter
         to avoid numerical issues.
Found heuristic solution: objective 639443.96087
Presolve removed 113846 rows and 48 columns
Presolve time: 0.38s
Presolved: 20330 rows, 20789 columns, 98926 nonzeros
Variable types: 1 continuous, 20788 integer (20787 binary)
Warning: Markowitz tolerance tightened to 0.125

Root simplex log...

Iteration    Objective       Primal Inf.    Dual Inf.      Time
   34081    5.4621982e+04   7.331882e+04   0.000000e+00      5s
   44246    5.7036570e+04   0.000000e+00   0.000000e+00      9s

Root relaxation: objective 5.703657e+04, 44246 iterations, 8.47 seconds (8.27 work units)
Total elapsed time = 10.06s

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0 57036.5704    0 11081 639443.961 57036.5704  91.1%     -   10s
H    0     0                    609203.13367 57036.5704  90.6%     -   10s
H    0     0                    608048.46186 57036.5704  90.6%     -   13s
H    0     0                    463376.42267 57036.5704  87.7%     -   13s
H    0     0                    367233.71671 69801.9066  81.0%     -   15s
H    0     0                    320355.97529 69801.9066  78.2%     -   15s
H    0     0                    234601.67738 69801.9066  70.2%     -   15s
     0     0 75297.9320    0 7438 234601.677 75297.9320  67.9%     -   15s
H    0     0                    184800.48798 75297.9320  59.3%     -   16s
     0     0 77413.6787    0 6069 184800.488 77413.6787  58.1%     -   16s
     0     0 79343.3898    0 6280 184800.488 79343.3898  57.1%     -   17s
     0     0 79980.7557    0 6479 184800.488 79980.7557  56.7%     -   18s
     0     0 81289.4811    0 6925 184800.488 81289.4811  56.0%     -   19s
     0     0 81572.1567    0 7178 184800.488 81572.1567  55.9%     -   21s
     0     0 81572.1567    0 7308 184800.488 81572.1567  55.9%     -   21s
     0     0 81572.1567    0 7346 184800.488 81572.1567  55.9%     -   22s
     0     0 81572.1567    0 7334 184800.488 81572.1567  55.9%     -   22s
     0     0 81572.1567    0 7346 184800.488 81572.1567  55.9%     -   22s
     0     0 81572.1567    0 7329 184800.488 81572.1567  55.9%     -   22s
     0     0 81572.1567    0 7317 184800.488 81572.1567  55.9%     -   22s
H    0     0                    172407.54595 81572.1567  52.7%     -   23s
     0     0 87784.9852    0 7319 172407.546 87784.9852  49.1%     -   23s
     0     0 87784.9852    0 7319 172407.546 87784.9852  49.1%     -   23s
H    0     0                    165361.06952 88629.0964  46.4%     -   26s
     0     0 88629.0964    0  721 165361.070 88629.0964  46.4%     -   26s
H    0     0                    121577.91908 88629.0964  27.1%     -   26s
H    0     0                    118333.72877 88629.0964  25.1%     -   26s
     0     0 88629.0964    0  692 118333.729 88629.0964  25.1%     -   27s
H    0     0                    90250.049448 88629.0964  1.80%     -   30s

Cutting planes:
  Gomory: 113
  Lift-and-project: 259
  Cover: 4
  MIR: 6
  StrongCG: 1
  Flow cover: 1
  Zero half: 5113

Explored 1 nodes (103120 simplex iterations) in 30.20 seconds (28.50 work units)
Thread count was 48 (of 96 available processors)

Solution count 10: 90250 118334 121578 ... 463376

Optimal solution found (tolerance 5.00e-02)
Best objective 9.025004944801e+04, best bound 8.862909636841e+04, gap 1.7961%
coll_cache:optimal_local_rate=0.217992,0.209415,0.213205,0.262847,0.225787,0.198578,0.217054,0.269525,
coll_cache:optimal_remote_rate=0.677964,0.686542,0.682752,0.63311,0.670169,0.697378,0.678902,0.626431,
coll_cache:optimal_cpu_rate=0.104044,0.104044,0.104044,0.104044,0.104044,0.104044,0.104044,0.104044,
z=90250
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=5441819648
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=5441819648
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=5441819648
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=5441819648
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=5441819648
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=5441819648
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=5441819648
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=5441819648
    [Step(average) Profiler Level 1 E3 S999]
        L1  sample           0.008361 | send           0.000000
        L1  recv             0.000000 | copy           0.053888 | convert time 0.000000 | train  0.020236
        L1  feature nbytes    2.21 GB | label nbytes 0.00 Bytes
        L1  id nbytes      0.00 Bytes | graph nbytes 0.00 Bytes
        L1  miss nbytes     239.88 MB | remote nbytes    1.48 GB
        L1  num nodes               0 | num samples           0
        L1  seq duration     0.000000 | refresh duration   0.000000
    [Step(average) Profiler Level 2 E3 S999]
        L2  shuffle     0.000000 | core sample  0.000000 | id remap        0.000000
        L2  graph copy  0.000000 | id copy      0.000000 | cache feat copy 0.053888
        L2  last layer sample time 0.000000 | size 0.000000
    [Step(average) Profiler Level 3 E3 S999]
        L3  khop sample coo  0.000000 | khop sort coo      0.000000 | khop count edge     0.000000 | khop compact edge 0.000000
        L3  walk sample coo  0.000000 | walk topk total    0.000000 | walk topk step1     0.000000 | walk topk step2   0.000000
        L3  walk topk step3  0.000000 | walk topk step4    0.000000 | walk topk step5     0.000000
        L3  walk topk step6  0.000000 | walk topk step7    0.000000
        L3  remap unique     0.000000 | remap populate     0.000000 | remap mapnode       0.000000 | remap mapedge     0.000000
        L3  cache get_index  0.001946 | cache copy_index   0.000000 | cache extract_miss  0.000000
        L3  cache copy_miss  0.000000 | cache combine_miss 0.051863 | cache combine cache 0.008174 | cache combine remote 0.014616
        L3  label extract  0.000000
    [Profiler Level Percentiles E3 S999]
        p50.00_tail_logl2featcopy=0.053967
        p90.00_tail_logl2featcopy=0.056588
        p95.00_tail_logl2featcopy=0.057693
        p99.00_tail_logl2featcopy=0.059175
        p99.90_tail_logl2featcopy=0.079128
[CUDA] cuda: usage: 21.41 GB
creating_intra_node_communicator root=4, local_size=4, world_size=8
Rank=4, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.007324, per step: 0.000059
presamping
presamping takes 19.428796768188477
Rank=3, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.012141, per step: 0.000097
presamping
presamping takes 20.018526554107666
Rank=7, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.005969, per step: 0.000048
presamping
presamping takes 19.088923931121826
config:eval_tsp="2023-04-15 04:01:04"
config:num_worker=8
config:num_intra_size=4
config:root_dir=/nvme/songxiaoniu/graph-learning/wholegraph
config:graph_name=com-friendster
config:epochs=4
config:batchsize=4000
config:skip_epoch=2
config:local_step=125
config:presc_epoch=2
config:neighbors=10,25
config:hiddensize=256
config:num_layer=2
config:model=sage
config:framework=dgl
config:dataloaderworkers=0
config:dropout=0.5
config:lr=0.003
config:use_nccl=False
config:use_amp=True
config:use_collcache=True
config:cache_percentage=0.08
config:cache_policy=coll_cache_asymm_link
config:omp_thread_num=48
config:unsupervised=True
config:classnum=100
config:global_barrier=<multiprocessing.synchronize.Barrier object at 0x7feb595d5400>
config:worker_id=0
creating_intra_node_communicator root=0, local_size=4, world_size=8
Rank=0, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.005735, per step: 0.000046
epoch=4 total_steps=500
presamping
presamping takes 20.187370538711548
start training...
[Epoch 0], time=11.844038248062134, loss=0.6931472420692444
[Epoch 1], time=10.299236059188843, loss=0.6931472420692444
[Epoch 2], time=10.345648288726807, loss=0.6931472420692444
[Epoch 3], time=10.313277959823608, loss=0.6931472420692444
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  151445 KB |    1429 MB |    1552 GB |    1551 GB |
|       from large pool |  141050 KB |    1419 MB |    1538 GB |    1538 GB |
|       from small pool |   10394 KB |      14 MB |      13 GB |      13 GB |
|---------------------------------------------------------------------------|
| Active memory         |  151445 KB |    1429 MB |    1552 GB |    1551 GB |
|       from large pool |  141050 KB |    1419 MB |    1538 GB |    1538 GB |
|       from small pool |   10394 KB |      14 MB |      13 GB |      13 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    6106 MB |    6106 MB |    6106 MB |       0 B  |
|       from large pool |    6086 MB |    6086 MB |    6086 MB |       0 B  |
|       from small pool |      20 MB |      20 MB |      20 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   39019 KB |    1207 MB |    1293 GB |    1293 GB |
|       from large pool |   30981 KB |    1199 MB |    1278 GB |    1278 GB |
|       from small pool |    8037 KB |       9 MB |      14 GB |      14 GB |
|---------------------------------------------------------------------------|
| Allocations           |      58    |      74    |  102450    |  102392    |
|       from large pool |      12    |      22    |   32281    |   32269    |
|       from small pool |      46    |      57    |   70169    |   70123    |
|---------------------------------------------------------------------------|
| Active allocs         |      58    |      74    |  102450    |  102392    |
|       from large pool |      12    |      22    |   32281    |   32269    |
|       from small pool |      46    |      57    |   70169    |   70123    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      30    |      30    |      30    |       0    |
|       from large pool |      20    |      20    |      20    |       0    |
|       from small pool |      10    |      10    |      10    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      26    |      40    |   36597    |   36571    |
|       from large pool |       6    |      19    |   18393    |   18387    |
|       from small pool |      20    |      27    |   18204    |   18184    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[TRAIN_TIME] train time is 42.803638 seconds
[EPOCH_TIME] 10.700910 seconds, maybe large due to not enough epoch skipped.
[EPOCH_TIME] 10.329668 seconds
Rank=6, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.007579, per step: 0.000061
presamping
presamping takes 19.313354015350342
Rank=2, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.008909, per step: 0.000071
presamping
presamping takes 20.006304025650024
Rank=1, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.012113, per step: 0.000097
presamping
presamping takes 20.501094341278076
Rank=5, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.007483, per step: 0.000060
presamping
presamping takes 19.486425399780273

