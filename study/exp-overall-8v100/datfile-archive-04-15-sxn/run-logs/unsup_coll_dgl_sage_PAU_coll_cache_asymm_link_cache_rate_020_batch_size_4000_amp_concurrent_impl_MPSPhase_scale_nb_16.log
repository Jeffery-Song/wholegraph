succeed=True
[CUDA] cuda: usage: 5.42 GB
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID
Set parameter TimeLimit to value 200
Set parameter MIPGap to value 0.05
Set parameter ScaleFlag to value 1
Set parameter DegenMoves to value 2
Set parameter Cuts to value 2
Set parameter LogFile to value "cppsolver.log"
Set parameter Threads to value 48
Academic license - for non-commercial use only - registered to xiaoniu.sxn@sjtu.edu.cn
Gurobi Optimizer version 9.5.2 build v9.5.2rc0 (linux64)
Thread count: 48 physical cores, 96 logical processors, using up to 48 threads
Academic license - for non-commercial use only - registered to xiaoniu.sxn@sjtu.edu.cn
Optimize a model with 114112 rows, 17721 columns and 286904 nonzeros
Model fingerprint: 0x41d8b10f
Variable types: 9 continuous, 17712 integer (17712 binary)
Coefficient statistics:
  Matrix range     [5e-09, 5e+04]
  Objective range  [1e+00, 1e+00]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 7e+04]
Warning: Model contains large matrix coefficient range
         Consider reformulating model or setting NumericFocus parameter
         to avoid numerical issues.
Found heuristic solution: objective 364335.46192
Presolve removed 96782 rows and 7 columns
Presolve time: 0.31s
Presolved: 17330 rows, 17714 columns, 84307 nonzeros
Variable types: 1 continuous, 17713 integer (17712 binary)

Root simplex log...

Iteration    Objective       Primal Inf.    Dual Inf.      Time
   28581    1.2447383e+04   9.826806e+05   0.000000e+00      5s
   31508    1.2461833e+04   0.000000e+00   0.000000e+00      7s

Root relaxation: objective 1.246183e+04, 31508 iterations, 6.38 seconds (6.90 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0 12461.8334    0 7465 364335.462 12461.8334  96.6%     -    6s
H    0     0                    239970.12438 12461.8334  94.8%     -    7s
H    0     0                    239911.78294 12461.8334  94.8%     -    7s
H    0     0                    223456.29551 12461.8334  94.4%     -   11s
H    0     0                    136229.64096 12461.8334  90.9%     -   11s
H    0     0                    122023.45777 12461.8334  89.8%     -   11s
H    0     0                    112560.21997 12905.5589  88.5%     -   13s
H    0     0                    110729.76116 12905.5589  88.3%     -   13s
H    0     0                    102155.28146 12905.5589  87.4%     -   13s
H    0     0                    98496.331637 12905.5589  86.9%     -   13s
     0     0 12905.5589    0 5686 98496.3316 12905.5589  86.9%     -   13s
H    0     0                    98278.499642 12905.5589  86.9%     -   14s
H    0     0                    81618.193375 12905.5589  84.2%     -   14s
H    0     0                    53374.352291 13187.2829  75.3%     -   19s
H    0     0                    47667.863473 13187.2829  72.3%     -   19s
H    0     0                    46829.129189 13187.2829  71.8%     -   19s
H    0     0                    41656.195280 13187.2829  68.3%     -   19s
H    0     0                    40818.358048 13187.2829  67.7%     -   19s
H    0     0                    38773.590753 13187.2829  66.0%     -   19s
H    0     0                    36585.043048 13187.2829  64.0%     -   19s
H    0     0                    34391.346708 13187.2829  61.7%     -   19s
     0     0 13370.3745    0 4296 34391.3467 13370.3745  61.1%     -   19s
     0     0 13370.3745    0 4834 34391.3467 13370.3745  61.1%     -   22s
H    0     0                    32262.623462 13390.3490  58.5%     -   31s
     0     0 13399.6601    0 4577 32262.6235 13399.6601  58.5%     -   31s
     0     0 13399.6601    0 4769 32262.6235 13399.6601  58.5%     -   32s
     0     0 13399.6601    0 4818 32262.6235 13399.6601  58.5%     -   33s
     0     0 13399.6601    0 4801 32262.6235 13399.6601  58.5%     -   33s
H    0     0                    24886.768177 13399.6601  46.2%     -   34s
     0     0 13399.6601    0 4798 24886.7682 13399.6601  46.2%     -   34s
     0     0 13399.6601    0 4836 24886.7682 13399.6601  46.2%     -   35s
     0     0 13399.6601    0 4822 24886.7682 13399.6601  46.2%     -   35s
H    0     0                    21994.419176 13652.5770  37.9%     -   53s
H    0     0                    20653.189103 13652.5770  33.9%     -   53s
H    0     0                    17213.469322 13652.5770  20.7%     -   53s
H    0     0                    14521.258127 13652.5770  5.98%     -   53s
     0     0 13664.2552    0 2417 14521.2581 13664.2552  5.90%     -   53s
     0     0 13680.3622    0 1393 14521.2581 13680.3622  5.79%     -   56s
     0     0 13682.2629    0 1302 14521.2581 13682.2629  5.78%     -   56s
     0     0 13682.2629    0 1238 14521.2581 13682.2629  5.78%     -   56s
H    0     0                    14020.841738 13687.7204  2.38%     -   62s
     0     0 13687.7204    0  572 14020.8417 13687.7204  2.38%     -   62s

Cutting planes:
  Gomory: 106
  Lift-and-project: 170
  MIR: 2
  Flow cover: 8
  Zero half: 3195

Explored 1 nodes (126893 simplex iterations) in 62.01 seconds (64.91 work units)
Thread count was 48 (of 96 available processors)

Solution count 10: 14020.8 14521.3 17213.5 ... 38773.6

Optimal solution found (tolerance 5.00e-02)
Best objective 1.402084173830e+04, best bound 1.368772038162e+04, gap 2.3759%
coll_cache:optimal_local_rate=0.392578,0.391436,0.432094,0.391138,0.393726,0.39305,0.392154,0.421443,
coll_cache:optimal_remote_rate=0.593623,0.594765,0.554107,0.595063,0.592475,0.593152,0.594047,0.564758,
coll_cache:optimal_cpu_rate=0.0137988,0.0137988,0.0137988,0.0137988,0.0137988,0.0137988,0.0137988,0.0137988,
z=14020.8
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=11429402112
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=11429402112
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=11429402112
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=11429402112
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=11429402112
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=11429402112
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=11429402112
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=11429402112
    [Step(average) Profiler Level 1 E3 S999]
        L1  sample           0.007829 | send           0.000000
        L1  recv             0.000000 | copy           0.014511 | convert time 0.000000 | train  0.013082
        L1  feature nbytes    1.07 GB | label nbytes 0.00 Bytes
        L1  id nbytes      0.00 Bytes | graph nbytes 0.00 Bytes
        L1  miss nbytes      18.76 MB | remote nbytes  637.54 MB
        L1  num nodes               0 | num samples           0
        L1  seq duration     0.000000 | refresh duration   0.000000
    [Step(average) Profiler Level 2 E3 S999]
        L2  shuffle     0.000000 | core sample  0.000000 | id remap        0.000000
        L2  graph copy  0.000000 | id copy      0.000000 | cache feat copy 0.014511
        L2  last layer sample time 0.000000 | size 0.000000
    [Step(average) Profiler Level 3 E3 S999]
        L3  khop sample coo  0.000000 | khop sort coo      0.000000 | khop count edge     0.000000 | khop compact edge 0.000000
        L3  walk sample coo  0.000000 | walk topk total    0.000000 | walk topk step1     0.000000 | walk topk step2   0.000000
        L3  walk topk step3  0.000000 | walk topk step4    0.000000 | walk topk step5     0.000000
        L3  walk topk step6  0.000000 | walk topk step7    0.000000
        L3  remap unique     0.000000 | remap populate     0.000000 | remap mapnode       0.000000 | remap mapedge     0.000000
        L3  cache get_index  0.001937 | cache copy_index   0.000000 | cache extract_miss  0.000000
        L3  cache copy_miss  0.000000 | cache combine_miss 0.005655 | cache combine cache 0.000949 | cache combine remote 0.011558
        L3  label extract  0.000000
    [Profiler Level Percentiles E3 S999]
        p50.00_tail_logl2featcopy=0.014482
        p90.00_tail_logl2featcopy=0.015163
        p95.00_tail_logl2featcopy=0.015267
        p99.00_tail_logl2featcopy=0.015552
        p99.90_tail_logl2featcopy=0.029676
[CUDA] cuda: usage: 22.71 GB
Rank=1, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.012204, per step: 0.000098
presamping
presamping takes 22.35819697380066
Rank=2, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.006963, per step: 0.000056
presamping
presamping takes 22.361862897872925
config:eval_tsp="2023-04-14 21:42:22"
config:num_worker=8
config:num_intra_size=4
config:root_dir=/nvme/songxiaoniu/graph-learning/wholegraph
config:graph_name=ogbn-papers100M
config:epochs=4
config:batchsize=4000
config:skip_epoch=2
config:local_step=125
config:presc_epoch=2
config:neighbors=10,25
config:hiddensize=256
config:num_layer=2
config:model=sage
config:framework=dgl
config:dataloaderworkers=0
config:dropout=0.5
config:lr=0.003
config:use_nccl=False
config:use_amp=True
config:use_collcache=True
config:cache_percentage=0.2
config:cache_policy=coll_cache_asymm_link
config:omp_thread_num=48
config:unsupervised=True
config:classnum=172
config:global_barrier=<multiprocessing.synchronize.Barrier object at 0x7fa52553f400>
config:worker_id=0
creating_intra_node_communicator root=0, local_size=4, world_size=8
Rank=0, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.005659, per step: 0.000045
epoch=4 total_steps=500
presamping
presamping takes 21.271686792373657
start training...
[Epoch 0], time=6.0229105949401855, loss=0.6931472420692444
[Epoch 1], time=4.423771619796753, loss=0.6931472420692444
[Epoch 2], time=4.423895835876465, loss=0.6931472420692444
[Epoch 3], time=4.462970733642578, loss=0.6931472420692444
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  140406 KB |     784 MB |    1207 GB |    1207 GB |
|       from large pool |  130279 KB |     775 MB |    1194 GB |    1194 GB |
|       from small pool |   10126 KB |      14 MB |      13 GB |      13 GB |
|---------------------------------------------------------------------------|
| Active memory         |  140406 KB |     784 MB |    1207 GB |    1207 GB |
|       from large pool |  130279 KB |     775 MB |    1194 GB |    1194 GB |
|       from small pool |   10126 KB |      14 MB |      13 GB |      13 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    1394 MB |    1394 MB |    1394 MB |       0 B  |
|       from large pool |    1374 MB |    1374 MB |    1374 MB |       0 B  |
|       from small pool |      20 MB |      20 MB |      20 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   31626 KB |     890 MB |    1163 GB |    1163 GB |
|       from large pool |   27416 KB |     886 MB |    1149 GB |    1149 GB |
|       from small pool |    4209 KB |       9 MB |      13 GB |      13 GB |
|---------------------------------------------------------------------------|
| Allocations           |      58    |      74    |  102440    |  102382    |
|       from large pool |      11    |      21    |   32270    |   32259    |
|       from small pool |      47    |      58    |   70170    |   70123    |
|---------------------------------------------------------------------------|
| Active allocs         |      58    |      74    |  102440    |  102382    |
|       from large pool |      11    |      21    |   32270    |   32259    |
|       from small pool |      47    |      58    |   70170    |   70123    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      25    |      25    |      25    |       0    |
|       from large pool |      15    |      15    |      15    |       0    |
|       from small pool |      10    |      10    |      10    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      26    |      40    |   32828    |   32802    |
|       from large pool |       8    |      18    |   16410    |   16402    |
|       from small pool |      18    |      28    |   16418    |   16400    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[TRAIN_TIME] train time is 19.335260 seconds
[EPOCH_TIME] 4.833815 seconds, maybe large due to not enough epoch skipped.
[EPOCH_TIME] 4.443717 seconds
creating_intra_node_communicator root=4, local_size=4, world_size=8
Rank=4, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.007337, per step: 0.000059
presamping
presamping takes 22.18198251724243
Rank=3, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.012157, per step: 0.000097
presamping
presamping takes 21.98326873779297
Rank=5, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.005727, per step: 0.000046
presamping
presamping takes 22.345786571502686
Rank=7, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.005863, per step: 0.000047
presamping
presamping takes 21.507575750350952
Rank=6, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.005873, per step: 0.000047
presamping
presamping takes 21.32026767730713

