succeed=True
[CUDA] cuda: usage: 5.23 GB
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID
Set parameter TimeLimit to value 200
Set parameter MIPGap to value 0.05
Set parameter ScaleFlag to value 1
Set parameter DegenMoves to value 2
Set parameter Cuts to value 2
Set parameter LogFile to value "cppsolver.log"
Set parameter Threads to value 48
Academic license - for non-commercial use only - registered to xiaoniu.sxn@sjtu.edu.cn
Gurobi Optimizer version 9.5.2 build v9.5.2rc0 (linux64)
Thread count: 48 physical cores, 96 logical processors, using up to 48 threads
Academic license - for non-commercial use only - registered to xiaoniu.sxn@sjtu.edu.cn
Optimize a model with 146056 rows, 22682 columns and 367248 nonzeros
Model fingerprint: 0x81846c3b
Variable types: 9 continuous, 22673 integer (22673 binary)
Coefficient statistics:
  Matrix range     [8e-09, 6e+05]
  Objective range  [1e+00, 1e+00]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 6e+04]
Warning: Model contains large matrix coefficient range
         Consider reformulating model or setting NumericFocus parameter
         to avoid numerical issues.
Found heuristic solution: objective 2.000000e+09
Presolve removed 124528 rows and 624 columns
Presolve time: 0.33s
Presolved: 21528 rows, 22058 columns, 64560 nonzeros
Found heuristic solution: objective 361506.93888
Variable types: 0 continuous, 22058 integer (22058 binary)

Root relaxation: objective 2.406334e+05, 25264 iterations, 0.84 seconds (0.79 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0 240633.388    0 10241 361506.939 240633.388  33.4%     -    1s
H    0     0                    358651.19370 240633.388  32.9%     -    1s
H    0     0                    329748.18450 240633.388  27.0%     -    1s
H    0     0                    318611.62618 240633.388  24.5%     -    3s
H    0     0                    310410.29374 240633.388  22.5%     -    3s
H    0     0                    298512.53699 240633.388  19.4%     -    3s
H    0     0                    291322.48503 246578.235  15.4%     -    6s
H    0     0                    285559.86391 246578.235  13.7%     -    6s
H    0     0                    284341.94406 246578.235  13.3%     -    6s
     0     0 246578.235    0 6691 284341.944 246578.235  13.3%     -    6s
H    0     0                    268440.20913 246578.235  8.14%     -    7s
     0     0 249729.757    0 4472 268440.209 249729.757  6.97%     -    7s
     0     0 249729.757    0 4475 268440.209 249729.757  6.97%     -    7s
     0     0 251284.426    0 4982 268440.209 251284.426  6.39%     -    8s
H    0     0                    267557.49441 251284.426  6.08%     -    8s
     0     0 251503.197    0 5239 267557.494 251503.197  6.00%     -    9s
     0     0 252126.916    0 5337 267557.494 252126.916  5.77%     -    9s
     0     0 252453.269    0 5526 267557.494 252453.269  5.65%     -   10s
     0     0 252479.118    0 5634 267557.494 252479.118  5.64%     -   11s
     0     0 252492.365    0 5739 267557.494 252492.365  5.63%     -   11s
H    0     0                    266865.79704 252556.159  5.36%     -   12s
H    0     0                    265140.96377 252556.159  4.75%     -   12s
     0     0 252556.159    0 5717 265140.964 252556.159  4.75%     -   12s

Cutting planes:
  Gomory: 119
  Lift-and-project: 133
  MIR: 2
  Zero half: 3040
  Mod-K: 1860

Explored 1 nodes (50785 simplex iterations) in 12.17 seconds (10.64 work units)
Thread count was 48 (of 96 available processors)

Solution count 10: 265141 266866 267557 ... 318612

Optimal solution found (tolerance 5.00e-02)
Best objective 2.651409637713e+05, best bound 2.525561593091e+05, gap 4.7465%
coll_cache:optimal_local_rate=0.0931115,0.0983239,0.0923753,0.100301,0.0917833,0.0938679,0.0924559,0.0894285,
coll_cache:optimal_remote_rate=0.247019,0.241807,0.247755,0.239829,0.248347,0.246263,0.247675,0.250702,
coll_cache:optimal_cpu_rate=0.65987,0.65987,0.65987,0.65987,0.65987,0.65987,0.65987,0.65987,
z=265141
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=739012608
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=739012608
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=739012608
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=739012608
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=739012608
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=739012608
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=739012608
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=739012608
    [Step(average) Profiler Level 1 E3 S999]
        L1  sample           0.004752 | send           0.000000
        L1  recv             0.000000 | copy           0.177374 | convert time 0.000000 | train  0.020514
        L1  feature nbytes    1.19 GB | label nbytes 0.00 Bytes
        L1  id nbytes      0.00 Bytes | graph nbytes 0.00 Bytes
        L1  miss nbytes     802.45 MB | remote nbytes  297.73 MB
        L1  num nodes               0 | num samples           0
        L1  seq duration     0.000000 | refresh duration   0.000000
    [Step(average) Profiler Level 2 E3 S999]
        L2  shuffle     0.000000 | core sample  0.000000 | id remap        0.000000
        L2  graph copy  0.000000 | id copy      0.000000 | cache feat copy 0.177374
        L2  last layer sample time 0.000000 | size 0.000000
    [Step(average) Profiler Level 3 E3 S999]
        L3  khop sample coo  0.000000 | khop sort coo      0.000000 | khop count edge     0.000000 | khop compact edge 0.000000
        L3  walk sample coo  0.000000 | walk topk total    0.000000 | walk topk step1     0.000000 | walk topk step2   0.000000
        L3  walk topk step3  0.000000 | walk topk step4    0.000000 | walk topk step5     0.000000
        L3  walk topk step6  0.000000 | walk topk step7    0.000000
        L3  remap unique     0.000000 | remap populate     0.000000 | remap mapnode       0.000000 | remap mapedge     0.000000
        L3  cache get_index  0.000837 | cache copy_index   0.000000 | cache extract_miss  0.000000
        L3  cache copy_miss  0.000000 | cache combine_miss 0.176445 | cache combine cache 0.001779 | cache combine remote 0.003207
        L3  label extract  0.000000
    [Profiler Level Percentiles E3 S999]
        p50.00_tail_logl2featcopy=0.177648
        p90.00_tail_logl2featcopy=0.187187
        p95.00_tail_logl2featcopy=0.189951
        p99.00_tail_logl2featcopy=0.195174
        p99.90_tail_logl2featcopy=0.198126
[CUDA] cuda: usage: 12.13 GB
Rank=3, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.007643, per step: 0.000061
presamping
presamping takes 12.479424715042114
Rank=1, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.007480, per step: 0.000060
presamping
presamping takes 12.537689685821533
config:eval_tsp="2023-04-15 00:38:58"
config:num_worker=8
config:num_intra_size=4
config:root_dir=/nvme/songxiaoniu/graph-learning/wholegraph
config:graph_name=com-friendster
config:epochs=4
config:batchsize=2000
config:skip_epoch=2
config:local_step=125
config:presc_epoch=2
config:neighbors=10,25
config:hiddensize=256
config:num_layer=2
config:model=sage
config:framework=dgl
config:dataloaderworkers=0
config:dropout=0.5
config:lr=0.003
config:use_nccl=False
config:use_amp=True
config:use_collcache=True
config:cache_percentage=0.01
config:cache_policy=coll_cache_asymm_link
config:omp_thread_num=48
config:unsupervised=True
config:classnum=100
config:global_barrier=<multiprocessing.synchronize.Barrier object at 0x7fcf02563400>
config:worker_id=0
creating_intra_node_communicator root=0, local_size=4, world_size=8
Rank=0, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.004606, per step: 0.000037
epoch=4 total_steps=500
presamping
presamping takes 11.681361436843872
start training...
[Epoch 0], time=26.826791763305664, loss=0.6931472420692444
[Epoch 1], time=25.287581205368042, loss=0.6931472420692444
[Epoch 2], time=25.38619065284729, loss=0.6931472420692444
[Epoch 3], time=25.34285020828247, loss=0.6931472420692444
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   81255 KB |  783016 KB |     819 GB |     819 GB |
|       from large pool |   73961 KB |  776553 KB |     810 GB |     810 GB |
|       from small pool |    7293 KB |    9043 KB |       8 GB |       8 GB |
|---------------------------------------------------------------------------|
| Active memory         |   81255 KB |  783016 KB |     819 GB |     819 GB |
|       from large pool |   73961 KB |  776553 KB |     810 GB |     810 GB |
|       from small pool |    7293 KB |    9043 KB |       8 GB |       8 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2670 MB |    2670 MB |    2670 MB |       0 B  |
|       from large pool |    2658 MB |    2658 MB |    2658 MB |       0 B  |
|       from small pool |      12 MB |      12 MB |      12 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   66201 KB |  714263 KB |  724148 MB |  724083 MB |
|       from large pool |   63254 KB |  710924 KB |  715299 MB |  715238 MB |
|       from small pool |    2946 KB |    6393 KB |    8848 MB |    8845 MB |
|---------------------------------------------------------------------------|
| Allocations           |      58    |      74    |  102453    |  102395    |
|       from large pool |      12    |      22    |   31285    |   31273    |
|       from small pool |      46    |      57    |   71168    |   71122    |
|---------------------------------------------------------------------------|
| Active allocs         |      58    |      74    |  102453    |  102395    |
|       from large pool |      12    |      22    |   31285    |   31273    |
|       from small pool |      46    |      57    |   71168    |   71122    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      21    |      21    |      21    |       0    |
|       from large pool |      15    |      15    |      15    |       0    |
|       from small pool |       6    |       6    |       6    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      27    |      36    |   37788    |   37761    |
|       from large pool |      10    |      19    |   18875    |   18865    |
|       from small pool |      17    |      23    |   18913    |   18896    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[TRAIN_TIME] train time is 102.844835 seconds
[EPOCH_TIME] 25.711209 seconds, maybe large due to not enough epoch skipped.
[EPOCH_TIME] 25.364705 seconds
Rank=2, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.006106, per step: 0.000049
presamping
presamping takes 12.045539379119873
Rank=7, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.004660, per step: 0.000037
presamping
presamping takes 11.714530229568481
Rank=6, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.005029, per step: 0.000040
presamping
presamping takes 12.17655324935913
Rank=5, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.005318, per step: 0.000043
presamping
presamping takes 12.001564741134644
creating_intra_node_communicator root=4, local_size=4, world_size=8
Rank=4, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.005406, per step: 0.000043
presamping
presamping takes 12.396646976470947

