succeed=True
[CUDA] cuda: usage: 5.29 GB
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID
Set parameter TimeLimit to value 200
Set parameter MIPGap to value 0.05
Set parameter ScaleFlag to value 1
Set parameter DegenMoves to value 2
Set parameter Cuts to value 2
Set parameter LogFile to value "cppsolver.log"
Set parameter Threads to value 48
Academic license - for non-commercial use only - registered to xiaoniu.sxn@sjtu.edu.cn
Gurobi Optimizer version 9.5.2 build v9.5.2rc0 (linux64)
Thread count: 48 physical cores, 96 logical processors, using up to 48 threads
Academic license - for non-commercial use only - registered to xiaoniu.sxn@sjtu.edu.cn
Optimize a model with 134704 rows, 20919 columns and 338696 nonzeros
Model fingerprint: 0x70499703
Variable types: 9 continuous, 20910 integer (20910 binary)
Coefficient statistics:
  Matrix range     [5e-09, 1e+05]
  Objective range  [1e+00, 1e+00]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 3e+04]
Warning: Model contains large matrix coefficient range
         Consider reformulating model or setting NumericFocus parameter
         to avoid numerical issues.
Found heuristic solution: objective 189016.24464
Presolve removed 114399 rows and 131 columns
Presolve time: 0.35s
Presolved: 20305 rows, 20788 columns, 69476 nonzeros
Variable types: 1 continuous, 20787 integer (20787 binary)

Root relaxation: objective 7.060704e+04, 25432 iterations, 1.16 seconds (0.91 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0 70607.0388    0 11401 189016.245 70607.0388  62.6%     -    1s
H    0     0                    188926.19323 70607.0388  62.6%     -    1s
H    0     0                    155924.68429 70607.0388  54.7%     -    3s
H    0     0                    150099.43517 70609.1067  53.0%     -    4s
H    0     0                    139224.85725 70609.1067  49.3%     -    4s
H    0     0                    110504.85326 70609.1067  36.1%     -    4s
H    0     0                    110395.56530 79950.3649  27.6%     -    6s
H    0     0                    108011.31806 79950.3649  26.0%     -    6s
H    0     0                    104967.20129 79950.3649  23.8%     -    6s
     0     0 80365.8368    0 6586 104967.201 80365.8368  23.4%     -    6s
H    0     0                    103926.91430 80365.8368  22.7%     -    7s
H    0     0                    102102.43203 82667.5276  19.0%     -    8s
     0     0 82667.5276    0 5290 102102.432 82667.5276  19.0%     -    8s
H    0     0                    101405.74847 84171.2625  17.0%     -    9s
     0     0 84171.2625    0 5376 101405.748 84171.2625  17.0%     -    9s
     0     0 84954.5994    0 5442 101405.748 84954.5994  16.2%     -    9s
     0     0 85086.7708    0 5540 101405.748 85086.7708  16.1%     -    9s
     0     0 85139.6315    0 5574 101405.748 85139.6315  16.0%     -   10s
     0     0 85184.0983    0 5561 101405.748 85184.0983  16.0%     -   10s
H    0     0                    100339.24057 85202.0764  15.1%     -   10s
     0     0 85202.0764    0 5518 100339.241 85202.0764  15.1%     -   11s
     0     0 85218.4273    0 5529 100339.241 85218.4273  15.1%     -   11s
     0     0 85227.8731    0 5509 100339.241 85227.8731  15.1%     -   11s
     0     0 85233.8874    0 5513 100339.241 85233.8874  15.1%     -   11s
     0     0 85235.3890    0 5513 100339.241 85235.3890  15.1%     -   11s
     0     0 87779.2364    0 2322 100339.241 87779.2364  12.5%     -   14s
H    0     0                    97599.777347 87779.2364  10.1%     -   16s
     0     0 87806.3201    0 2139 97599.7773 87806.3201  10.0%     -   16s
     0     0 87806.3201    0 2020 97599.7773 87806.3201  10.0%     -   16s
H    0     0                    97132.684957 87806.3201  9.60%     -   18s
H    0     0                    96830.436252 87806.3201  9.32%     -   18s
H    0     0                    96483.650130 87806.3201  8.99%     -   18s
H    0     0                    95420.383310 87806.3201  7.98%     -   18s
     0     0 88595.3993    0  423 95420.3833 88595.3993  7.15%     -   18s
H    0     0                    90039.945087 88595.3993  1.60%     -   18s

Cutting planes:
  Gomory: 159
  Lift-and-project: 32
  MIR: 8
  StrongCG: 1
  Flow cover: 5
  Zero half: 3412
  Mod-K: 1451

Explored 1 nodes (53433 simplex iterations) in 18.78 seconds (14.94 work units)
Thread count was 48 (of 96 available processors)

Solution count 10: 90039.9 95420.4 96483.7 ... 103927

Optimal solution found (tolerance 5.00e-02)
Best objective 9.003994508683e+04, best bound 8.859539925694e+04, gap 1.6043%
coll_cache:optimal_local_rate=0.136362,0.144255,0.15083,0.172148,0.139102,0.148531,0.169868,0.146101,
coll_cache:optimal_remote_rate=0.462756,0.454863,0.448288,0.426969,0.460016,0.450587,0.42925,0.453017,
coll_cache:optimal_cpu_rate=0.400882,0.400882,0.400882,0.400882,0.400882,0.400882,0.400882,0.400882,
z=90039.9
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=2331370496
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=2331370496
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=2331370496
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=2331370496
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=2331370496
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=2331370496
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=2331370496
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=2331370496
    [Step(average) Profiler Level 1 E3 S999]
        L1  sample           0.004411 | send           0.000000
        L1  recv             0.000000 | copy           0.070399 | convert time 0.000000 | train  0.010152
        L1  feature nbytes  563.34 MB | label nbytes 0.00 Bytes
        L1  id nbytes      0.00 Bytes | graph nbytes 0.00 Bytes
        L1  miss nbytes     230.23 MB | remote nbytes  249.27 MB
        L1  num nodes               0 | num samples           0
        L1  seq duration     0.000000 | refresh duration   0.000000
    [Step(average) Profiler Level 2 E3 S999]
        L2  shuffle     0.000000 | core sample  0.000000 | id remap        0.000000
        L2  graph copy  0.000000 | id copy      0.000000 | cache feat copy 0.070399
        L2  last layer sample time 0.000000 | size 0.000000
    [Step(average) Profiler Level 3 E3 S999]
        L3  khop sample coo  0.000000 | khop sort coo      0.000000 | khop count edge     0.000000 | khop compact edge 0.000000
        L3  walk sample coo  0.000000 | walk topk total    0.000000 | walk topk step1     0.000000 | walk topk step2   0.000000
        L3  walk topk step3  0.000000 | walk topk step4    0.000000 | walk topk step5     0.000000
        L3  walk topk step6  0.000000 | walk topk step7    0.000000
        L3  remap unique     0.000000 | remap populate     0.000000 | remap mapnode       0.000000 | remap mapedge     0.000000
        L3  cache get_index  0.000913 | cache copy_index   0.000000 | cache extract_miss  0.000000
        L3  cache copy_miss  0.000000 | cache combine_miss 0.069398 | cache combine cache 0.001467 | cache combine remote 0.002759
        L3  label extract  0.000000
    [Profiler Level Percentiles E3 S999]
        p50.00_tail_logl2featcopy=0.070634
        p90.00_tail_logl2featcopy=0.073089
        p95.00_tail_logl2featcopy=0.073804
        p99.00_tail_logl2featcopy=0.074954
        p99.90_tail_logl2featcopy=0.079056
[CUDA] cuda: usage: 11.78 GB
Rank=2, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.005260, per step: 0.000042
presamping
presamping takes 13.064393281936646
creating_intra_node_communicator root=4, local_size=4, world_size=8
Rank=4, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.005391, per step: 0.000043
presamping
presamping takes 13.080061912536621
config:eval_tsp="2023-04-14 18:52:39"
config:num_worker=8
config:num_intra_size=4
config:root_dir=/nvme/songxiaoniu/graph-learning/wholegraph
config:graph_name=ogbn-papers100M
config:epochs=4
config:batchsize=2000
config:skip_epoch=2
config:local_step=125
config:presc_epoch=2
config:neighbors=10,25
config:hiddensize=256
config:num_layer=2
config:model=sage
config:framework=dgl
config:dataloaderworkers=0
config:dropout=0.5
config:lr=0.003
config:use_nccl=False
config:use_amp=True
config:use_collcache=True
config:cache_percentage=0.04
config:cache_policy=coll_cache_asymm_link
config:omp_thread_num=48
config:unsupervised=True
config:classnum=172
config:global_barrier=<multiprocessing.synchronize.Barrier object at 0x7f157bdcf400>
config:worker_id=0
creating_intra_node_communicator root=0, local_size=4, world_size=8
Rank=0, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.004539, per step: 0.000036
epoch=4 total_steps=500
presamping
presamping takes 11.948744297027588
start training...
[Epoch 0], time=12.214289426803589, loss=0.6931472420692444
[Epoch 1], time=10.622329950332642, loss=0.6931472420692444
[Epoch 2], time=10.613847970962524, loss=0.6931472420692444
[Epoch 3], time=10.651124715805054, loss=0.6931472420692444
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   75021 KB |  415812 KB |  646076 MB |  646002 MB |
|       from large pool |   68021 KB |  409386 KB |  637921 MB |  637854 MB |
|       from small pool |    7000 KB |    8913 KB |    8155 MB |    8148 MB |
|---------------------------------------------------------------------------|
| Active memory         |   75021 KB |  415812 KB |  646076 MB |  646002 MB |
|       from large pool |   68021 KB |  409386 KB |  637921 MB |  637854 MB |
|       from small pool |    7000 KB |    8913 KB |    8155 MB |    8148 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |     980 MB |     980 MB |     980 MB |       0 B  |
|       from large pool |     968 MB |     968 MB |     968 MB |       0 B  |
|       from small pool |      12 MB |      12 MB |      12 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   21235 KB |  612387 KB |     780 GB |     780 GB |
|       from large pool |   17995 KB |  608899 KB |     772 GB |     772 GB |
|       from small pool |    3240 KB |    6422 KB |       8 GB |       8 GB |
|---------------------------------------------------------------------------|
| Allocations           |      58    |      74    |  102444    |  102386    |
|       from large pool |      11    |      21    |   31274    |   31263    |
|       from small pool |      47    |      58    |   71170    |   71123    |
|---------------------------------------------------------------------------|
| Active allocs         |      58    |      74    |  102444    |  102386    |
|       from large pool |      11    |      21    |   31274    |   31263    |
|       from small pool |      47    |      58    |   71170    |   71123    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      17    |      17    |      17    |       0    |
|       from large pool |      11    |      11    |      11    |       0    |
|       from small pool |       6    |       6    |       6    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      25    |      34    |   34275    |   34250    |
|       from large pool |       5    |      14    |   17330    |   17325    |
|       from small pool |      20    |      24    |   16945    |   16925    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[TRAIN_TIME] train time is 44.103368 seconds
[EPOCH_TIME] 11.025842 seconds, maybe large due to not enough epoch skipped.
[EPOCH_TIME] 10.632773 seconds
Rank=1, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.007508, per step: 0.000060
presamping
presamping takes 12.57882046699524
Rank=7, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.005900, per step: 0.000047
presamping
presamping takes 12.32767367362976
Rank=5, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.004784, per step: 0.000038
presamping
presamping takes 13.588259220123291
Rank=3, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.007612, per step: 0.000061
presamping
presamping takes 12.548084259033203
Rank=6, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.004707, per step: 0.000038
presamping
presamping takes 12.947566270828247

