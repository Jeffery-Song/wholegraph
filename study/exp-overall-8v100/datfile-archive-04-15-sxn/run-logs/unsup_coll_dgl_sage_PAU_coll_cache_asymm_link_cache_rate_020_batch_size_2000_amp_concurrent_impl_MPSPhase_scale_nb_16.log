succeed=True
[CUDA] cuda: usage: 5.30 GB
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID
Set parameter TimeLimit to value 200
Set parameter MIPGap to value 0.05
Set parameter ScaleFlag to value 1
Set parameter DegenMoves to value 2
Set parameter Cuts to value 2
Set parameter LogFile to value "cppsolver.log"
Set parameter Threads to value 48
Academic license - for non-commercial use only - registered to xiaoniu.sxn@sjtu.edu.cn
Gurobi Optimizer version 9.5.2 build v9.5.2rc0 (linux64)
Thread count: 48 physical cores, 96 logical processors, using up to 48 threads
Academic license - for non-commercial use only - registered to xiaoniu.sxn@sjtu.edu.cn
Optimize a model with 112000 rows, 17393 columns and 281592 nonzeros
Model fingerprint: 0x8ef31332
Variable types: 9 continuous, 17384 integer (17384 binary)
Coefficient statistics:
  Matrix range     [5e-09, 2e+04]
  Objective range  [1e+00, 1e+00]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 3e+04]
Warning: Model contains large matrix coefficient range
         Consider reformulating model or setting NumericFocus parameter
         to avoid numerical issues.
Found heuristic solution: objective 189214.55115
Presolve removed 94990 rows and 7 columns
Presolve time: 0.29s
Presolved: 17010 rows, 17386 columns, 82379 nonzeros
Variable types: 1 continuous, 17385 integer (17384 binary)

Root simplex log...

Iteration    Objective       Primal Inf.    Dual Inf.      Time
   29723    6.4095340e+03   2.640071e-01   0.000000e+00      5s
   29993    6.4095315e+03   0.000000e+00   0.000000e+00      5s

Root relaxation: objective 6.409532e+03, 29993 iterations, 4.93 seconds (5.62 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0 6409.53151    0 7681 189214.551 6409.53151  96.6%     -    5s
H    0     0                    125285.32933 6409.53151  94.9%     -    5s
H    0     0                    124395.72293 6409.53151  94.8%     -    5s
H    0     0                    123452.81865 6409.53151  94.8%     -    9s
H    0     0                    60723.784727 6409.53151  89.4%     -    9s
H    0     0                    53646.066526 6409.53151  88.1%     -    9s
H    0     0                    48504.355992 6565.43579  86.5%     -   13s
H    0     0                    37305.773786 6565.43579  82.4%     -   13s
     0     0 6694.05287    0 6099 37305.7738 6694.05287  82.1%     -   13s
H    0     0                    37145.879456 6694.05287  82.0%     -   14s
H    0     0                    29217.501231 6694.05287  77.1%     -   14s
     0     0 6694.05287    0 5342 29217.5012 6694.05287  77.1%     -   15s
H    0     0                    24380.274791 6751.32957  72.3%     -   20s
H    0     0                    23553.584055 6751.32957  71.3%     -   20s
H    0     0                    22138.627270 6751.32957  69.5%     -   20s
H    0     0                    20380.797260 6751.32957  66.9%     -   20s
     0     0 6768.20084    0 5065 20380.7973 6768.20084  66.8%     -   20s
H    0     0                    18128.865814 6768.20084  62.7%     -   27s
H    0     0                    17197.060101 6768.20084  60.6%     -   27s
H    0     0                    13567.426654 6768.20084  50.1%     -   27s
H    0     0                    12636.400184 6768.20084  46.4%     -   27s
H    0     0                    11710.367466 6768.20084  42.2%     -   27s
     0     0 6772.71602    0 5755 11710.3675 6772.71602  42.2%     -   27s
     0     0 6772.71602    0 5621 11710.3675 6772.71602  42.2%     -   29s
     0     0 6772.71602    0 5559 11710.3675 6772.71602  42.2%     -   30s
     0     0 6772.71602    0 5552 11710.3675 6772.71602  42.2%     -   30s
H    0     0                    9738.8106897 6772.71602  30.5%     -   31s
     0     0 6772.71602    0 5523 9738.81069 6772.71602  30.5%     -   31s
     0     0 6772.71602    0 5607 9738.81069 6772.71602  30.5%     -   32s
     0     0 6772.71602    0 5585 9738.81069 6772.71602  30.5%     -   32s
     0     0 6772.71602    0 5564 9738.81069 6772.71602  30.5%     -   33s
H    0     0                    8940.7400410 6828.21721  23.6%     -   46s
H    0     0                    8874.7155686 6828.21721  23.1%     -   46s
H    0     0                    8460.0504397 6828.21721  19.3%     -   46s
     0     0 6865.06427    0 5309 8460.05044 6865.06427  18.9%     -   46s
H    0     0                    7680.3781464 6930.67918  9.76%     -   58s
     0     0 6930.67918    0 2942 7680.37815 6930.67918  9.76%     -   58s
     0     0 6937.97170    0 2190 7680.37815 6937.97170  9.67%     -   60s
     0     0 6938.26178    0 2036 7680.37815 6938.26178  9.66%     -   61s
     0     0 6958.52462    0 2010 7680.37815 6958.52462  9.40%     -   65s
H    0     0                    7259.0694729 6958.52462  4.14%     -   67s

Cutting planes:
  Gomory: 95
  Lift-and-project: 139
  Zero half: 4105

Explored 1 nodes (129650 simplex iterations) in 67.33 seconds (69.03 work units)
Thread count was 48 (of 96 available processors)

Solution count 10: 7259.07 7680.38 8460.05 ... 17197.1

Optimal solution found (tolerance 5.00e-02)
Best objective 7.259069472868e+03, best bound 6.958524615653e+03, gap 4.1403%
coll_cache:optimal_local_rate=0.390592,0.386819,0.390187,0.422972,0.388109,0.391175,0.39701,0.399785,
coll_cache:optimal_remote_rate=0.595515,0.599288,0.595919,0.563134,0.597997,0.594932,0.589097,0.586321,
coll_cache:optimal_cpu_rate=0.0138933,0.0138933,0.0138933,0.0138933,0.0138933,0.0138933,0.0138933,0.0138933,
z=7259.07
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=11429402112
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=11429402112
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=11429402112
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=11429402112
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=11429402112
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=11429402112
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=11429402112
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=11429402112
    [Step(average) Profiler Level 1 E3 S999]
        L1  sample           0.004341 | send           0.000000
        L1  recv             0.000000 | copy           0.007951 | convert time 0.000000 | train  0.007847
        L1  feature nbytes  563.39 MB | label nbytes 0.00 Bytes
        L1  id nbytes      0.00 Bytes | graph nbytes 0.00 Bytes
        L1  miss nbytes      11.29 MB | remote nbytes  330.56 MB
        L1  num nodes               0 | num samples           0
        L1  seq duration     0.000000 | refresh duration   0.000000
    [Step(average) Profiler Level 2 E3 S999]
        L2  shuffle     0.000000 | core sample  0.000000 | id remap        0.000000
        L2  graph copy  0.000000 | id copy      0.000000 | cache feat copy 0.007951
        L2  last layer sample time 0.000000 | size 0.000000
    [Step(average) Profiler Level 3 E3 S999]
        L3  khop sample coo  0.000000 | khop sort coo      0.000000 | khop count edge     0.000000 | khop compact edge 0.000000
        L3  walk sample coo  0.000000 | walk topk total    0.000000 | walk topk step1     0.000000 | walk topk step2   0.000000
        L3  walk topk step3  0.000000 | walk topk step4    0.000000 | walk topk step5     0.000000
        L3  walk topk step6  0.000000 | walk topk step7    0.000000
        L3  remap unique     0.000000 | remap populate     0.000000 | remap mapnode       0.000000 | remap mapedge     0.000000
        L3  cache get_index  0.001053 | cache copy_index   0.000000 | cache extract_miss  0.000000
        L3  cache copy_miss  0.000000 | cache combine_miss 0.003542 | cache combine cache 0.000533 | cache combine remote 0.006306
        L3  label extract  0.000000
    [Profiler Level Percentiles E3 S999]
        p50.00_tail_logl2featcopy=0.007987
        p90.00_tail_logl2featcopy=0.008265
        p95.00_tail_logl2featcopy=0.008311
        p99.00_tail_logl2featcopy=0.008989
        p99.90_tail_logl2featcopy=0.016554
[CUDA] cuda: usage: 21.51 GB
Rank=2, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.005198, per step: 0.000042
presamping
presamping takes 12.87559700012207
Rank=3, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.007660, per step: 0.000061
presamping
presamping takes 13.09844422340393
creating_intra_node_communicator root=4, local_size=4, world_size=8
Rank=4, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.005443, per step: 0.000044
presamping
presamping takes 13.101349353790283
Rank=6, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.004848, per step: 0.000039
presamping
presamping takes 13.672035694122314
Rank=1, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.007590, per step: 0.000061
presamping
presamping takes 13.330250024795532
Rank=7, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.004922, per step: 0.000039
presamping
presamping takes 12.755903482437134
config:eval_tsp="2023-04-14 19:51:33"
config:num_worker=8
config:num_intra_size=4
config:root_dir=/nvme/songxiaoniu/graph-learning/wholegraph
config:graph_name=ogbn-papers100M
config:epochs=4
config:batchsize=2000
config:skip_epoch=2
config:local_step=125
config:presc_epoch=2
config:neighbors=10,25
config:hiddensize=256
config:num_layer=2
config:model=sage
config:framework=dgl
config:dataloaderworkers=0
config:dropout=0.5
config:lr=0.003
config:use_nccl=False
config:use_amp=True
config:use_collcache=True
config:cache_percentage=0.2
config:cache_policy=coll_cache_asymm_link
config:omp_thread_num=48
config:unsupervised=True
config:classnum=172
config:global_barrier=<multiprocessing.synchronize.Barrier object at 0x7f8316abc400>
config:worker_id=0
creating_intra_node_communicator root=0, local_size=4, world_size=8
Rank=0, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.004708, per step: 0.000038
epoch=4 total_steps=500
presamping
presamping takes 13.249754667282104
start training...
[Epoch 0], time=4.132017612457275, loss=0.6931472420692444
[Epoch 1], time=2.570601224899292, loss=0.6931472420692444
[Epoch 2], time=2.5065670013427734, loss=0.6931472420692444
[Epoch 3], time=2.501296043395996, loss=0.6931472420692444
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   74745 KB |  417942 KB |  645805 MB |  645732 MB |
|       from large pool |   67732 KB |  411511 KB |  637652 MB |  637585 MB |
|       from small pool |    7013 KB |    8904 KB |    8153 MB |    8146 MB |
|---------------------------------------------------------------------------|
| Active memory         |   74745 KB |  417942 KB |  645805 MB |  645732 MB |
|       from large pool |   67732 KB |  411511 KB |  637652 MB |  637585 MB |
|       from small pool |    7013 KB |    8904 KB |    8153 MB |    8146 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  743424 KB |  743424 KB |  743424 KB |       0 B  |
|       from large pool |  731136 KB |  731136 KB |  731136 KB |       0 B  |
|       from small pool |   12288 KB |   12288 KB |   12288 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   62471 KB |  498203 KB |  606917 MB |  606856 MB |
|       from large pool |   59244 KB |  494716 KB |  598582 MB |  598525 MB |
|       from small pool |    3227 KB |    6422 KB |    8334 MB |    8331 MB |
|---------------------------------------------------------------------------|
| Allocations           |      58    |      74    |  102438    |  102380    |
|       from large pool |      11    |      21    |   31270    |   31259    |
|       from small pool |      47    |      58    |   71168    |   71121    |
|---------------------------------------------------------------------------|
| Active allocs         |      58    |      74    |  102438    |  102380    |
|       from large pool |      11    |      21    |   31270    |   31259    |
|       from small pool |      47    |      58    |   71168    |   71121    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      17    |      17    |      17    |       0    |
|       from large pool |      11    |      11    |      11    |       0    |
|       from small pool |       6    |       6    |       6    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      27    |      37    |   33599    |   33572    |
|       from large pool |      10    |      16    |   15903    |   15893    |
|       from small pool |      17    |      26    |   17696    |   17679    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[TRAIN_TIME] train time is 11.712023 seconds
[EPOCH_TIME] 2.928006 seconds, maybe large due to not enough epoch skipped.
[EPOCH_TIME] 2.504170 seconds
Rank=5, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.004745, per step: 0.000038
presamping
presamping takes 13.001134157180786

