succeed=True
[CUDA] cuda: usage: 5.18 GB
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID
Set parameter TimeLimit to value 200
Set parameter MIPGap to value 0.05
Set parameter ScaleFlag to value 1
Set parameter DegenMoves to value 2
Set parameter Cuts to value 2
Set parameter LogFile to value "cppsolver.log"
Set parameter Threads to value 48
Academic license - for non-commercial use only - registered to xiaoniu.sxn@sjtu.edu.cn
Gurobi Optimizer version 9.5.2 build v9.5.2rc0 (linux64)
Thread count: 48 physical cores, 96 logical processors, using up to 48 threads
Academic license - for non-commercial use only - registered to xiaoniu.sxn@sjtu.edu.cn
Optimize a model with 140248 rows, 21780 columns and 352640 nonzeros
Model fingerprint: 0x8df4304c
Variable types: 9 continuous, 21771 integer (21771 binary)
Coefficient statistics:
  Matrix range     [5e-09, 6e+03]
  Objective range  [1e+00, 1e+00]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 5e+03]
Warning: Model contains large matrix coefficient range
         Consider reformulating model or setting NumericFocus parameter
         to avoid numerical issues.
Found heuristic solution: objective 25027.121893
Presolve removed 119318 rows and 376 columns
Presolve time: 0.38s
Presolved: 20930 rows, 21404 columns, 100781 nonzeros
Variable types: 1 continuous, 21403 integer (21402 binary)

Deterministic concurrent LP optimizer: primal and dual simplex
Showing first log only...


Use crossover to convert LP symmetric solution to basic solution...
Concurrent spin time: 0.04s

Solved with primal simplex

Root relaxation: objective 2.032191e+03, 2782 iterations, 0.20 seconds (0.19 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0 2032.19127    0 11001 25027.1219 2032.19127  91.9%     -    0s
H    0     0                    23967.549408 2032.19127  91.5%     -    1s
H    0     0                    17492.122045 2032.19127  88.4%     -    2s
H    0     0                    15232.732412 2032.19127  86.7%     -    2s
H    0     0                    13913.259956 2032.19127  85.4%     -    2s
     0     0 2233.72181    0 8605 13913.2600 2233.72181  83.9%     -    4s
H    0     0                    13819.040008 2233.72181  83.8%     -    4s
H    0     0                    10645.133059 2233.72181  79.0%     -    4s
H    0     0                    8619.9003997 2398.78068  72.2%     -    5s
     0     0 2398.78068    0 5978 8619.90040 2398.78068  72.2%     -    5s
     0     0 2409.69962    0 5867 8619.90040 2409.69962  72.0%     -    5s
H    0     0                    5581.7509111 2409.69962  56.8%     -    6s
H    0     0                    5341.6803321 2467.94736  53.8%     -    7s
H    0     0                    3528.9724392 2467.94736  30.1%     -    7s
     0     0 2467.94736    0 6823 3528.97244 2467.94736  30.1%     -    7s
     0     0 2552.80215    0 6623 3528.97244 2552.80215  27.7%     -    8s
H    0     0                    3422.0184980 2559.80601  25.2%     -    8s
     0     0 2559.80601    0 6473 3422.01850 2559.80601  25.2%     -    8s
H    0     0                    3261.8395170 2561.67144  21.5%     -    9s
H    0     0                    3207.9965146 2561.67144  20.1%     -    9s
     0     0 2561.67144    0 6582 3207.99651 2561.67144  20.1%     -    9s
H    0     0                    3128.2851024 2562.31225  18.1%     -    9s
     0     0 2562.31225    0 6625 3128.28510 2562.31225  18.1%     -    9s
     0     0 2562.79470    0 6680 3128.28510 2562.79470  18.1%     -   10s
     0     0 2562.87931    0 6698 3128.28510 2562.87931  18.1%     -   10s
H    0     0                    3048.3994397 2562.87931  15.9%     -   12s
H    0     0                    3034.8114956 2731.54845  10.0%     -   13s
     0     0 2731.54845    0 1921 3034.81150 2731.54845  10.0%     -   13s
     0     0 2735.95980    0 1589 3034.81150 2735.95980  9.85%     -   13s
     0     0 2735.95980    0 1483 3034.81150 2735.95980  9.85%     -   13s
H    0     0                    3021.6820877 2735.95980  9.46%     -   14s
     0     0 2749.05501    0  769 3021.68209 2749.05501  9.02%     -   15s
     0     0 2749.75772    0  750 3021.68209 2749.75772  9.00%     -   15s
     0     0 2757.67004    0  432 3021.68209 2757.67004  8.74%     -   16s
H    0     0                    2876.5069790 2757.67004  4.13%     -   16s

Cutting planes:
  Gomory: 201
  Lift-and-project: 48
  MIR: 9
  Flow cover: 36
  Zero half: 1391
  Mod-K: 1931

Explored 1 nodes (30490 simplex iterations) in 16.82 seconds (13.80 work units)
Thread count was 48 (of 96 available processors)

Solution count 10: 2876.51 3021.68 3034.81 ... 5341.68

Optimal solution found (tolerance 5.00e-02)
Best objective 2.876506979049e+03, best bound 2.757670035827e+03, gap 4.1313%
coll_cache:optimal_local_rate=0.182586,0.308228,0.248545,0.189298,0.242199,0.272963,0.183618,0.219659,
coll_cache:optimal_remote_rate=0.735373,0.609732,0.669414,0.728661,0.675761,0.644997,0.734341,0.698301,
coll_cache:optimal_cpu_rate=0.0820403,0.0820403,0.0820403,0.0820403,0.0820403,0.0820403,0.0820403,0.0820403,
z=2876.51
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=1194116608
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=1194116608
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=1194116608
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=1194116608
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=1194116608
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=1194116608
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=1194116608
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=1194116608
    [Step(average) Profiler Level 1 E3 S143]
        L1  sample           0.004641 | send           0.000000
        L1  recv             0.000000 | copy           0.015095 | convert time 0.000000 | train  0.011611
        L1  feature nbytes  515.72 MB | label nbytes 0.00 Bytes
        L1  id nbytes      0.00 Bytes | graph nbytes 0.00 Bytes
        L1  miss nbytes      48.25 MB | remote nbytes  348.69 MB
        L1  num nodes               0 | num samples           0
        L1  seq duration     0.000000 | refresh duration   0.000000
    [Step(average) Profiler Level 2 E3 S143]
        L2  shuffle     0.000000 | core sample  0.000000 | id remap        0.000000
        L2  graph copy  0.000000 | id copy      0.000000 | cache feat copy 0.015095
        L2  last layer sample time 0.000000 | size 0.000000
    [Step(average) Profiler Level 3 E3 S143]
        L3  khop sample coo  0.000000 | khop sort coo      0.000000 | khop count edge     0.000000 | khop compact edge 0.000000
        L3  walk sample coo  0.000000 | walk topk total    0.000000 | walk topk step1     0.000000 | walk topk step2   0.000000
        L3  walk topk step3  0.000000 | walk topk step4    0.000000 | walk topk step5     0.000000
        L3  walk topk step6  0.000000 | walk topk step7    0.000000
        L3  remap unique     0.000000 | remap populate     0.000000 | remap mapnode       0.000000 | remap mapedge     0.000000
        L3  cache get_index  0.000957 | cache copy_index   0.000000 | cache extract_miss  0.000000
        L3  cache copy_miss  0.000000 | cache combine_miss 0.014075 | cache combine cache 0.001795 | cache combine remote 0.003610
        L3  label extract  0.000000
    [Profiler Level Percentiles E3 S143]
        p50.00_tail_logl2featcopy=0.015241
        p90.00_tail_logl2featcopy=0.018450
        p95.00_tail_logl2featcopy=0.018880
        p99.00_tail_logl2featcopy=0.021661
        p99.90_tail_logl2featcopy=0.025672
[CUDA] cuda: usage: 10.08 GB
creating_intra_node_communicator root=4, local_size=4, world_size=8
Rank=4, Graph loaded.
!!!!Train_dataloader(with 18 items) enumerate latency: 0.814577579498291
!!!!Train_data_list(with 18 items) enumerate latency: 1.2159347534179688e-05, transfer latency: 0.7784326076507568
presamping
presamping takes 1.6835219860076904
Rank=2, Graph loaded.
!!!!Train_dataloader(with 18 items) enumerate latency: 0.8865201473236084
!!!!Train_data_list(with 18 items) enumerate latency: 7.62939453125e-06, transfer latency: 0.8490035533905029
presamping
presamping takes 1.5727639198303223
Rank=7, Graph loaded.
!!!!Train_dataloader(with 18 items) enumerate latency: 0.8752777576446533
!!!!Train_data_list(with 18 items) enumerate latency: 7.3909759521484375e-06, transfer latency: 0.8409774303436279
presamping
presamping takes 1.473402976989746
Rank=5, Graph loaded.
!!!!Train_dataloader(with 18 items) enumerate latency: 0.8258981704711914
!!!!Train_data_list(with 18 items) enumerate latency: 5.7220458984375e-06, transfer latency: 0.7843217849731445
presamping
presamping takes 1.9477927684783936
config:eval_tsp="2023-04-15 05:54:46"
config:num_worker=8
config:num_intra_size=4
config:root_dir=/nvme/songxiaoniu/graph-learning/wholegraph
config:graph_name=ogbn-papers100M
config:epochs=4
config:batchsize=8000
config:skip_epoch=2
config:local_step=125
config:presc_epoch=2
config:neighbors=10,25
config:hiddensize=256
config:num_layer=2
config:model=sage
config:framework=dgl
config:dataloaderworkers=0
config:dropout=0.5
config:lr=0.003
config:use_nccl=False
config:use_amp=True
config:use_collcache=True
config:cache_percentage=0.02
config:cache_policy=coll_cache_asymm_link
config:omp_thread_num=48
config:unsupervised=False
config:classnum=172
config:global_barrier=<multiprocessing.synchronize.Barrier object at 0x7fefe7a4c3d0>
config:worker_id=0
creating_intra_node_communicator root=0, local_size=4, world_size=8
Rank=0, Graph loaded.
!!!!Train_dataloader(with 18 items) enumerate latency: 0.8270492553710938
!!!!Train_data_list(with 18 items) enumerate latency: 7.152557373046875e-06, transfer latency: 0.7996170520782471
epoch=4 total_steps=72
presamping
presamping takes 1.5666453838348389
start training...
[Epoch 0], time=2.021845817565918, loss=5.099424839019775
[Epoch 1], time=0.5672774314880371, loss=5.050938129425049
[Epoch 2], time=0.5671083927154541, loss=5.005175590515137
[Epoch 3], time=0.5628674030303955, loss=4.9621453285217285
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   68872 KB |  369825 KB |   96003 MB |   95936 MB |
|       from large pool |   62536 KB |  363726 KB |   94854 MB |   94793 MB |
|       from small pool |    6335 KB |    8755 KB |    1149 MB |    1142 MB |
|---------------------------------------------------------------------------|
| Active memory         |   68872 KB |  369825 KB |   96003 MB |   95936 MB |
|       from large pool |   62536 KB |  363726 KB |   94854 MB |   94793 MB |
|       from small pool |    6335 KB |    8755 KB |    1149 MB |    1142 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |     800 MB |     800 MB |     800 MB |       0 B  |
|       from large pool |     788 MB |     788 MB |     788 MB |       0 B  |
|       from small pool |      12 MB |      12 MB |      12 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   21240 KB |  300228 KB |   70875 MB |   70855 MB |
|       from large pool |   19383 KB |  295955 KB |   69697 MB |   69678 MB |
|       from small pool |    1856 KB |    5504 KB |    1178 MB |    1176 MB |
|---------------------------------------------------------------------------|
| Allocations           |      55    |      69    |   11485    |   11430    |
|       from large pool |      11    |      22    |    4168    |    4157    |
|       from small pool |      44    |      49    |    7317    |    7273    |
|---------------------------------------------------------------------------|
| Active allocs         |      55    |      69    |   11485    |   11430    |
|       from large pool |      11    |      22    |    4168    |    4157    |
|       from small pool |      44    |      49    |    7317    |    7273    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      20    |      20    |      20    |       0    |
|       from large pool |      14    |      14    |      14    |       0    |
|       from small pool |       6    |       6    |       6    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      19    |      34    |    4625    |    4606    |
|       from large pool |       6    |      17    |    2675    |    2669    |
|       from small pool |      13    |      21    |    1950    |    1937    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[TRAIN_TIME] train time is 3.720178 seconds
[EPOCH_TIME] 0.930045 seconds, maybe large due to not enough epoch skipped.
[EPOCH_TIME] 0.565203 seconds
Rank=1, Graph loaded.
!!!!Train_dataloader(with 18 items) enumerate latency: 0.8372905254364014
!!!!Train_data_list(with 18 items) enumerate latency: 6.198883056640625e-06, transfer latency: 0.7978744506835938
presamping
presamping takes 1.7058844566345215
Rank=6, Graph loaded.
!!!!Train_dataloader(with 18 items) enumerate latency: 0.8081414699554443
!!!!Train_data_list(with 18 items) enumerate latency: 5.9604644775390625e-06, transfer latency: 0.7772259712219238
presamping
presamping takes 1.6868908405303955
Rank=3, Graph loaded.
!!!!Train_dataloader(with 18 items) enumerate latency: 0.8090777397155762
!!!!Train_data_list(with 18 items) enumerate latency: 5.9604644775390625e-06, transfer latency: 0.7749662399291992
presamping
presamping takes 1.6649906635284424

