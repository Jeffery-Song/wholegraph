succeed=True
[CUDA] cuda: usage: 5.32 GB
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
0 : local 72, cpu 8 {link #0 : g3 24}, {link #1 : g6 24}, {link #2 : g1 12}, {link #3 : g2 12},
1 : local 72, cpu 8 {link #0 : g7 24}, {link #1 : g2 24}, {link #2 : g3 12}, {link #3 : g0 12},
2 : local 72, cpu 8 {link #0 : g1 24}, {link #1 : g3 24}, {link #2 : g0 12}, {link #3 : g4 12},
3 : local 72, cpu 8 {link #0 : g2 24}, {link #1 : g0 24}, {link #2 : g5 12}, {link #3 : g1 12},
4 : local 72, cpu 8 {link #0 : g5 24}, {link #1 : g7 24}, {link #2 : g2 12}, {link #3 : g6 12},
5 : local 72, cpu 8 {link #0 : g6 24}, {link #1 : g4 24}, {link #2 : g7 12}, {link #3 : g3 12},
6 : local 72, cpu 8 {link #0 : g0 24}, {link #1 : g5 24}, {link #2 : g4 12}, {link #3 : g7 12},
7 : local 72, cpu 8 {link #0 : g4 24}, {link #1 : g1 24}, {link #2 : g6 12}, {link #3 : g5 12},
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID
Set parameter TimeLimit to value 200
Set parameter MIPGap to value 0.05
Set parameter ScaleFlag to value 1
Set parameter DegenMoves to value 2
Set parameter Cuts to value 2
Set parameter LogFile to value "cppsolver.log"
Set parameter Threads to value 48
Academic license - for non-commercial use only - registered to xiaoniu.sxn@sjtu.edu.cn
Gurobi Optimizer version 9.5.2 build v9.5.2rc0 (linux64)
Thread count: 48 physical cores, 96 logical processors, using up to 48 threads
Academic license - for non-commercial use only - registered to xiaoniu.sxn@sjtu.edu.cn
Optimize a model with 131008 rows, 20345 columns and 329400 nonzeros
Model fingerprint: 0x3d0911b0
Variable types: 9 continuous, 20336 integer (20336 binary)
Coefficient statistics:
  Matrix range     [8e-09, 1e+05]
  Objective range  [1e+00, 1e+00]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 1e+05]
Warning: Model contains large matrix coefficient range
         Consider reformulating model or setting NumericFocus parameter
         to avoid numerical issues.
Found heuristic solution: objective 2.000000e+09
Presolve removed 111118 rows and 7 columns
Presolve time: 0.36s
Presolved: 19890 rows, 20338 columns, 96675 nonzeros
Found heuristic solution: objective 652336.76671
Variable types: 1 continuous, 20337 integer (20336 binary)

Root simplex log...

Iteration    Objective       Primal Inf.    Dual Inf.      Time
   27583    2.2312441e+04   7.846312e+03   0.000000e+00      5s
   31487    2.3045214e+04   0.000000e+00   0.000000e+00      7s

Root relaxation: objective 2.304521e+04, 31487 iterations, 6.16 seconds (6.90 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0 23045.2136    0 8785 652336.767 23045.2136  96.5%     -    7s
H    0     0                    469108.71771 23045.2136  95.1%     -    7s
H    0     0                    469072.77352 23045.2136  95.1%     -    7s
H    0     0                    240844.47421 23045.2136  90.4%     -   10s
H    0     0                    206387.85091 23780.5938  88.5%     -   15s
     0     0 23780.5938    0 7027 206387.851 23780.5938  88.5%     -   15s
H    0     0                    144534.48773 23780.5938  83.5%     -   17s
H    0     0                    135865.80967 24105.2944  82.3%     -   19s
H    0     0                    107567.87935 24105.2944  77.6%     -   19s
     0     0 24105.2944    0 6800 107567.879 24105.2944  77.6%     -   19s
     0     0 24443.6730    0 6504 107567.879 24443.6730  77.3%     -   22s
     0     0 24690.4880    0 6744 107567.879 24690.4880  77.0%     -   25s
     0     0 24808.0729    0 7297 107567.879 24808.0729  76.9%     -   28s
     0     0 24832.1231    0 7535 107567.879 24832.1231  76.9%     -   29s
     0     0 24834.7558    0 7509 107567.879 24834.7558  76.9%     -   30s
     0     0 24837.6473    0 7319 107567.879 24837.6473  76.9%     -   30s
     0     0 24838.8985    0 7340 107567.879 24838.8985  76.9%     -   30s
     0     0 24839.6928    0 7347 107567.879 24839.6928  76.9%     -   31s
     0     0 24840.0440    0 7347 107567.879 24840.0440  76.9%     -   32s
     0     0 24840.0440    0 7363 107567.879 24840.0440  76.9%     -   32s
H    0     0                    105333.64542 25235.6804  76.0%     -   47s
H    0     0                    100179.94774 25235.6804  74.8%     -   47s
H    0     0                    91588.079585 25235.6804  72.4%     -   47s
H    0     0                    78505.666338 25235.6804  67.9%     -   47s
H    0     0                    73373.657611 25235.6804  65.6%     -   47s
H    0     0                    62789.788089 25235.6804  59.8%     -   47s
H    0     0                    57647.444344 25235.6804  56.2%     -   47s
H    0     0                    48669.628177 25235.6804  48.1%     -   47s
H    0     0                    48516.935357 25235.6804  48.0%     -   47s
H    0     0                    43508.840855 25235.6804  42.0%     -   47s
H    0     0                    42487.225352 25235.6804  40.6%     -   47s
H    0     0                    40284.993751 25235.6804  37.4%     -   47s
     0     0 25235.6804    0 4568 40284.9938 25235.6804  37.4%     -   47s
H    0     0                    35551.925212 25498.7801  28.3%     -   54s
     0     0 25498.7801    0 1545 35551.9252 25498.7801  28.3%     -   54s
     0     0 25500.2646    0 1462 35551.9252 25500.2646  28.3%     -   55s
H    0     0                    33107.142222 25500.2646  23.0%     -   59s
H    0     0                    33028.342602 25500.2646  22.8%     -   59s
H    0     0                    32547.287264 25500.2646  21.7%     -   59s
     0     0 25570.6738    0  701 32547.2873 25570.6738  21.4%     -   63s
H    0     0                    32235.151781 25570.6738  20.7%     -   63s
H    0     0                    27405.278463 25570.6738  6.69%     -   63s
H    0     0                    25908.835472 25570.6738  1.31%     -   71s

Cutting planes:
  Gomory: 60
  Lift-and-project: 102
  Zero half: 4742

Explored 1 nodes (117479 simplex iterations) in 71.42 seconds (75.22 work units)
Thread count was 48 (of 96 available processors)

Solution count 10: 25908.8 27405.3 32235.2 ... 43508.8

Optimal solution found (tolerance 5.00e-02)
Best objective 2.590883547235e+04, best bound 2.557067375066e+04, gap 1.3052%
coll_cache:optimal_local_rate=0.347383,0.346989,0.356666,0.356947,0.346725,0.346194,0.348021,0.354099,
coll_cache:optimal_remote_rate=0.637006,0.6374,0.627723,0.627442,0.637664,0.638195,0.636368,0.63029,
coll_cache:optimal_cpu_rate=0.0156109,0.0156109,0.0156109,0.0156109,0.0156109,0.0156109,0.0156109,0.0156109,
z=25908.8
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=10816456704
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=10816456704
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=10816456704
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=10816456704
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=10816456704
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=10816456704
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=10816456704
test_result:init:feat_nbytes=67182966784
test_result:init:cache_nbytes=10816456704
    [Step(average) Profiler Level 1 E3 S999]
        L1  sample           0.008404 | send           0.000000
        L1  recv             0.000000 | copy           0.017729 | convert time 0.000000 | train  0.018384
        L1  feature nbytes    2.21 GB | label nbytes 0.00 Bytes
        L1  id nbytes      0.00 Bytes | graph nbytes 0.00 Bytes
        L1  miss nbytes      40.20 MB | remote nbytes    1.40 GB
        L1  num nodes               0 | num samples           0
        L1  seq duration     0.000000 | refresh duration   0.000000
    [Step(average) Profiler Level 2 E3 S999]
        L2  shuffle     0.000000 | core sample  0.000000 | id remap        0.000000
        L2  graph copy  0.000000 | id copy      0.000000 | cache feat copy 0.017729
        L2  last layer sample time 0.000000 | size 0.000000
    [Step(average) Profiler Level 3 E3 S999]
        L3  khop sample coo  0.000000 | khop sort coo      0.000000 | khop count edge     0.000000 | khop compact edge 0.000000
        L3  walk sample coo  0.000000 | walk topk total    0.000000 | walk topk step1     0.000000 | walk topk step2   0.000000
        L3  walk topk step3  0.000000 | walk topk step4    0.000000 | walk topk step5     0.000000
        L3  walk topk step6  0.000000 | walk topk step7    0.000000
        L3  remap unique     0.000000 | remap populate     0.000000 | remap mapnode       0.000000 | remap mapedge     0.000000
        L3  cache get_index  0.002006 | cache copy_index   0.000000 | cache extract_miss  0.000000
        L3  cache copy_miss  0.000000 | cache combine_miss 0.008988 | cache combine cache 0.001539 | cache combine remote 0.014117
        L3  label extract  0.000000
    [Profiler Level Percentiles E3 S999]
        p50.00_tail_logl2featcopy=0.017922
        p90.00_tail_logl2featcopy=0.018711
        p95.00_tail_logl2featcopy=0.018839
        p99.00_tail_logl2featcopy=0.019118
        p99.90_tail_logl2featcopy=0.042289
[CUDA] cuda: usage: 23.58 GB
creating_intra_node_communicator root=4, local_size=4, world_size=8
Rank=4, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.007330, per step: 0.000059
presamping
presamping takes 20.5345356464386
Rank=5, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.007418, per step: 0.000059
presamping
presamping takes 20.510672569274902
Rank=6, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.006692, per step: 0.000054
presamping
presamping takes 19.47044324874878
Rank=1, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.012100, per step: 0.000097
presamping
presamping takes 19.33445119857788
Rank=2, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.009300, per step: 0.000074
presamping
presamping takes 20.59732699394226
config:eval_tsp="2023-04-15 04:35:40"
config:num_worker=8
config:num_intra_size=4
config:root_dir=/nvme/songxiaoniu/graph-learning/wholegraph
config:graph_name=com-friendster
config:epochs=4
config:batchsize=4000
config:skip_epoch=2
config:local_step=125
config:presc_epoch=2
config:neighbors=10,25
config:hiddensize=256
config:num_layer=2
config:model=sage
config:framework=dgl
config:dataloaderworkers=0
config:dropout=0.5
config:lr=0.003
config:use_nccl=False
config:use_amp=True
config:use_collcache=True
config:cache_percentage=0.16
config:cache_policy=coll_cache_asymm_link
config:omp_thread_num=48
config:unsupervised=True
config:classnum=100
config:global_barrier=<multiprocessing.synchronize.Barrier object at 0x7f6d6d09f400>
config:worker_id=0
creating_intra_node_communicator root=0, local_size=4, world_size=8
Rank=0, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.005554, per step: 0.000044
epoch=4 total_steps=500
presamping
presamping takes 19.352924823760986
start training...
[Epoch 0], time=7.137238264083862, loss=0.6931472420692444
[Epoch 1], time=5.57434344291687, loss=0.6931472420692444
[Epoch 2], time=5.5745017528533936, loss=0.6931472420692444
[Epoch 3], time=5.571452617645264, loss=0.6931472420692444
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  151965 KB |    1430 MB |    1551 GB |    1551 GB |
|       from large pool |  141560 KB |    1420 MB |    1537 GB |    1537 GB |
|       from small pool |   10405 KB |      14 MB |      13 GB |      13 GB |
|---------------------------------------------------------------------------|
| Active memory         |  151965 KB |    1430 MB |    1551 GB |    1551 GB |
|       from large pool |  141560 KB |    1420 MB |    1537 GB |    1537 GB |
|       from small pool |   10405 KB |      14 MB |      13 GB |      13 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2694 MB |    2694 MB |    2694 MB |       0 B  |
|       from large pool |    2674 MB |    2674 MB |    2674 MB |       0 B  |
|       from small pool |      20 MB |      20 MB |      20 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   91746 KB |    1233 MB |    1286 GB |    1286 GB |
|       from large pool |   85768 KB |    1227 MB |    1272 GB |    1272 GB |
|       from small pool |    5978 KB |       9 MB |      14 GB |      14 GB |
|---------------------------------------------------------------------------|
| Allocations           |      58    |      74    |  102426    |  102368    |
|       from large pool |      12    |      22    |   32261    |   32249    |
|       from small pool |      46    |      57    |   70165    |   70119    |
|---------------------------------------------------------------------------|
| Active allocs         |      58    |      74    |  102426    |  102368    |
|       from large pool |      12    |      22    |   32261    |   32249    |
|       from small pool |      46    |      57    |   70165    |   70119    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      27    |      27    |      27    |       0    |
|       from large pool |      17    |      17    |      17    |       0    |
|       from small pool |      10    |      10    |      10    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      28    |      40    |   37846    |   37818    |
|       from large pool |       8    |      19    |   18720    |   18712    |
|       from small pool |      20    |      27    |   19126    |   19106    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[TRAIN_TIME] train time is 23.859237 seconds
[EPOCH_TIME] 5.964809 seconds, maybe large due to not enough epoch skipped.
[EPOCH_TIME] 5.573240 seconds
Rank=3, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.012113, per step: 0.000097
presamping
presamping takes 19.967946529388428
Rank=7, Graph loaded.
!!!!dist_homo_graph enumerate latency per epoch: 0.005646, per step: 0.000045
presamping
presamping takes 19.464641332626343

